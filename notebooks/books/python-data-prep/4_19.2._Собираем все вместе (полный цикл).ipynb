{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7g-aS09aNwxg"
   },
   "outputs": [],
   "source": [
    "# импортируем библиотеки numpy и pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# импортируем функцию train_test_split(), с помощью\n",
    "# которой разбиваем данные на обучающие и тестовые\n",
    "from sklearn.model_selection import train_test_split\n",
    "# импортируем классы BaseEstimator и TransformerMixin, \n",
    "# позволяющие написать собственные классы\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# импортируем класс SimpleImputer, позволяющий\n",
    "# выполнить импутацию пропусков\n",
    "from sklearn.impute import SimpleImputer\n",
    "# импортируем класс StandardScaler, позволяющий выполнить стандартизацию\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# импортируем класс OneHotEncoder, позволяющий выполнить дамми-кодирование\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# импортируем класс LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# импортируем функцию roc_auc_score() для вычисления AUC-ROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# импортируем класс ColumnTransformer, позволяющий выполнять\n",
    "# преобразования для отдельных типов столбцов\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# импортируем класс FunctionTransformer, позволяющий\n",
    "# задавать пользовательские функции\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# импортируем класс Pipeline, позволяющий создавать конвейеры\n",
    "from sklearn.pipeline import Pipeline\n",
    "# импортируем класс GridSearchCV, позволяющий \n",
    "# выполнить поиск по сетке\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XJUTB8AHNwxi"
   },
   "outputs": [],
   "source": [
    "# считываем данные\n",
    "data = pd.read_csv('Data/cs-training.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BO6nztUKNwxk"
   },
   "outputs": [],
   "source": [
    "# пишем функцию предварительной подготовки\n",
    "def preprocessing(df):\n",
    "    \n",
    "    # значения переменной age меньше 18 заменяем\n",
    "    # минимально допустимым значением возраста\n",
    "    df['age'] = np.where(df['age'] < 18, 18, df['age'])\n",
    "    \n",
    "    # создаем переменную Ratio - отношение количества \n",
    "    # просрочек 90+ к общему количеству просрочек\n",
    "    sum_of_delinq = (df['NumberOfTimes90DaysLate'] + \n",
    "                     df['NumberOfTime30-59DaysPastDueNotWorse'] + \n",
    "                     df['NumberOfTime60-89DaysPastDueNotWorse'])\n",
    "\n",
    "    cond = (df['NumberOfTimes90DaysLate'] == 0) | (sum_of_delinq == 0)\n",
    "    df['Ratio'] = np.where(\n",
    "        cond, 0, df['NumberOfTimes90DaysLate'] / sum_of_delinq)\n",
    "    \n",
    "    # создаем индикатор нулевых значений переменной \n",
    "    # NumberOfOpenCreditLinesAndLoans\n",
    "    df['NumberOfOpenCreditLinesAndLoans_is_0'] = np.where(\n",
    "        df['NumberOfOpenCreditLinesAndLoans'] == 0, 'T', 'F')\n",
    "    \n",
    "    # создаем индикатор нулевых значений переменной \n",
    "    # NumberRealEstateLoansOrLines\n",
    "    df['NumberRealEstateLoansOrLines_is_0'] = np.where(\n",
    "        df['NumberRealEstateLoansOrLines'] == 0, 'T', 'F')\n",
    "    \n",
    "    # создаем индикатор нулевых значений переменной \n",
    "    # RevolvingUtilizationOfUnsecuredLines\n",
    "    df['RevolvingUtilizationOfUnsecuredLines_is_0'] = np.where(\n",
    "        df['RevolvingUtilizationOfUnsecuredLines'] == 0, 'T', 'F')\n",
    "    \n",
    "    # преобразовываем переменные в категориальные, применив\n",
    "    # биннинг и перевод в единый строковый формат\n",
    "    for col in ['NumberOfTime30-59DaysPastDueNotWorse', \n",
    "                'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "                'NumberOfTimes90DaysLate']:\n",
    "        df.loc[df[col] > 3, col] = 4\n",
    "        df[col] = df[col].apply(lambda x: f\"cat_{x}\")\n",
    "        \n",
    "    # создаем список списков - список 2-факторных взаимодействий\n",
    "    lst = [\n",
    "        ['NumberOfDependents', \n",
    "         'NumberOfTime30-59DaysPastDueNotWorse'],\n",
    "        ['NumberOfTime60-89DaysPastDueNotWorse', \n",
    "         'NumberOfTimes90DaysLate'],\n",
    "        ['NumberOfTime30-59DaysPastDueNotWorse', \n",
    "         'NumberOfTime60-89DaysPastDueNotWorse'],\n",
    "        ['NumberRealEstateLoansOrLines_is_0', \n",
    "         'NumberOfTimes90DaysLate'],\n",
    "        ['NumberOfOpenCreditLinesAndLoans_is_0', \n",
    "         'NumberOfTimes90DaysLate']\n",
    "    ]\n",
    "    \n",
    "    # создаем взаимодействия\n",
    "    for i in lst:\n",
    "        f1 = i[0]\n",
    "        f2 = i[1]\n",
    "        df[f1 + ' + ' + f2 + '_interact'] = (df[f1].astype(str) + ' + ' \n",
    "                                             + df[f2].astype(str))\n",
    "\n",
    "    # укрупняем редкие категории\n",
    "    interact_columns = df.columns[df.columns.str.contains('interact')]\n",
    "    for col in interact_columns:\n",
    "        df.loc[df[col].value_counts()[df[col]].values < 55, col] = 'Other'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J5DKZD34Nwxl"
   },
   "outputs": [],
   "source": [
    "# применяем нашу функцию\n",
    "data = preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aKFlPA82Nwxm"
   },
   "outputs": [],
   "source": [
    "# создаем обучающий массив признаков, обучающий массив меток,\n",
    "# тестовый массив признаков, тестовый массив меток\n",
    "train, test, y_train, y_test = train_test_split(\n",
    "    data.drop('SeriousDlqin2yrs', axis=1), \n",
    "    data['SeriousDlqin2yrs'], \n",
    "    test_size=.3, \n",
    "    stratify=data['SeriousDlqin2yrs'], \n",
    "    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mr66UCKyNwxm"
   },
   "outputs": [],
   "source": [
    "# создаем собственный класс NumberOfDependentsReplacer, который\n",
    "# заменяет пропуски переменной NumberOfDependents\n",
    "# на определенное константное значение\n",
    "class NumberOfDependentsReplacer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "        threshold: пороговое значение\n",
    "        replace_value: значение, \n",
    "        на которое заменяем\n",
    "    \"\"\"\n",
    "    def __init__(self, replace_value=0):\n",
    "        self.replace_value = replace_value\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_replaced = np.where(X.isnull(), self.replace_value, X)\n",
    "        return X_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lPT-DXGmNwxn"
   },
   "outputs": [],
   "source": [
    "# создаем собственный класс MonthlyIncomeReplacer, который\n",
    "# заменяет пропуски и значения переменной MonthlyIncome\n",
    "# ниже заданного порога на определенное константное значение\n",
    "class MonthlyIncomeReplacer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "        threshold: пороговое значение\n",
    "        replace_value: значение, \n",
    "        на которое заменяем\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=1200, replace_value=1200):\n",
    "        self.threshold = threshold\n",
    "        self.replace_value = replace_value\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_trans = np.where((X.isnull()) | (X < self.threshold), \n",
    "                           self.replace_value, X)\n",
    "        return X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uuBGcDHwNwxn"
   },
   "outputs": [],
   "source": [
    "# создаем собственный класс UtilizationThresholdSetter, который\n",
    "# заменяет значения переменной RevolvingUtilizationOfUnsecuredLines\n",
    "# выше заданного порога на пропуски\n",
    "class UtilizationThresholdSetter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "        threshold: пороговое значение\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=2):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_trans = np.where(X > self.threshold, np.NaN, X)\n",
    "        return X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0VupffXXNwxo"
   },
   "outputs": [],
   "source": [
    "# создаем собственный класс, выполняющий биннинг\n",
    "class CustomDiscretizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "        bins: список бинов.\n",
    "    \"\"\"\n",
    "    def __init__(self, bins=np.arange(0, 1.05, 0.05)):\n",
    "        self.bins = bins\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # fit опять бездельничает\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # transform выполняет всю работу: применяет преобразование \n",
    "        # с помощью заданного значения параметра bins\n",
    "        self.bins[0] = -1\n",
    "        X_bin = np.digitize(X, self.bins).astype('object')\n",
    "        return X_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QGPcDRE7Nwxo"
   },
   "outputs": [],
   "source": [
    "# создаем собственный класс, выполняющий винзоризацию\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "    lower_quantile: float, по умолчанию 0\n",
    "        Нижний квантиль.\n",
    "    upper_quantile: float, по умолчанию 0.75\n",
    "        Верхний квантиль.\n",
    "    k: float, по умолчанию 1.5\n",
    "        Коэффициент.\n",
    "    copy: bool, по умолчанию True\n",
    "        Возвращает копию.\n",
    "    \"\"\"\n",
    "    def __init__(self, copy=True, lower_quantile=0, \n",
    "                 upper_quantile=0.75, k=1.5):\n",
    "        # все параметры для инициализации публичных атрибутов \n",
    "        # должны быть заданы в методе __init__\n",
    "        \n",
    "        # публичные атрибуты\n",
    "        self.copy = copy\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "        self.k = k\n",
    "        \n",
    "    def __is_numpy(self, X):\n",
    "        # частный метод, который с помощью функции isinstance()\n",
    "        # проверяет, является ли наш объект массивом NumPy\n",
    "        return isinstance(X, np.ndarray)\n",
    "                \n",
    "    def fit(self, X, y=None):\n",
    "        # fit должен принимать в качестве аргументов X и y\n",
    "        \n",
    "        # обучение модели осуществляется прямо здесь\n",
    "        # создаем пустой словарь, в котором ключами\n",
    "        # будут имена/целые числа, а значениями - кортежами\n",
    "        self._dict = {}\n",
    "        \n",
    "        # если 1D-массив, то переводим в 2D\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        # записываем количество столбцов\n",
    "        ncols = X.shape[1]\n",
    "        \n",
    "        # записываем результат __is_numpy()\n",
    "        is_np = self.__is_numpy(X)\n",
    "        \n",
    "        # если объект - массив NumPy, выполняем следующие действия:\n",
    "        if is_np:\n",
    "            # по каждому столбцу массива NumPy\n",
    "            for col in range(ncols):\n",
    "                lower = np.quantile(X[:, col], self.lower_quantile)\n",
    "                upper = np.quantile(X[:, col], self.upper_quantile)\n",
    "                IQR = (upper - lower) * self.k\n",
    "                self._dict[col] = (lower, upper, IQR)\n",
    "        # в противном случае, т.е. если объект - датафрейм pandas,\n",
    "        # выполняем следующие действия:\n",
    "        else:\n",
    "            # по каждому столбцу датафрейма pandas\n",
    "            for col in X.columns:\n",
    "                # вычисляем и записываем в словарь\n",
    "                lower = X[col].quantile(self.lower_quantile)\n",
    "                upper = X[col].quantile(self.upper_quantile)\n",
    "                IQR = (upper - lower) * self.k\n",
    "                self._dict[col] = (lower, upper, IQR)\n",
    "\n",
    "        # fit возвращает self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # transform принимает в качестве аргумента только X\n",
    "        \n",
    "        # выполняем копирование массива во избежание \n",
    "        # предупреждения SettingWithCopyWarning\n",
    "        # \"A value is trying to be set on a copy of \n",
    "        # a slice from a DataFrame (Происходит попытка изменить \n",
    "        # значение в копии среза данных датафрейма)\"\n",
    "        if self.copy:\n",
    "            X = X.copy()\n",
    "        \n",
    "        # если 1D-массив, то переводим в 2D\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        # записываем количество столбцов\n",
    "        ncols = X.shape[1]\n",
    "        \n",
    "        # записываем результат __is_numpy()\n",
    "        is_np = self.__is_numpy(X)\n",
    "        \n",
    "        # применяем преобразование к X\n",
    "        # если объект - массив NumPy, выполняем следующие действия:\n",
    "        if is_np:\n",
    "            # по каждому столбцу массива NumPy\n",
    "            for col in range(ncols):\n",
    "                # заменяем\n",
    "                X[:, col] = np.where(\n",
    "                    X[:, col] < (self._dict[col][0] - self._dict[col][2]), \n",
    "                    self._dict[col][0] - self._dict[col][2], \n",
    "                    X[:, col])\n",
    "                X[:, col] = np.where(\n",
    "                    X[:, col] >= (self._dict[col][1] + self._dict[col][2]), \n",
    "                    self._dict[col][1] + self._dict[col][2], \n",
    "                    X[:, col])\n",
    "                \n",
    "        # в противном случае, т.е. если объект - датафрейм pandas,\n",
    "        # выполняем следующие действия:\n",
    "        else:\n",
    "            # по каждому столбцу датафрейма pandas\n",
    "            for col in X.columns:\n",
    "                # заменяем\n",
    "                X[col] = np.where(\n",
    "                    X[col] < (self._dict[col][0] - self._dict[col][2]), \n",
    "                    self._dict[col][0] - self._dict[col][2], \n",
    "                    X[col])\n",
    "                X[col] = np.where(\n",
    "                    X[col] >= (self._dict[col][1] + self._dict[col][2]), \n",
    "                    self._dict[col][1] + self._dict[col][2], \n",
    "                    X[col]) \n",
    "        # transform возвращает X\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oS-h2duxNwxp"
   },
   "outputs": [],
   "source": [
    "# создаем список категориальных переменных\n",
    "cat_columns = train.dtypes[train.dtypes == 'object'].index.tolist()\n",
    "# создаем список количественных переменных\n",
    "num_columns = train.dtypes[train.dtypes != 'object'].index.tolist()\n",
    "# создаем список с переменной NumberOfDependents\n",
    "numberofdependents = ['NumberOfDependents']\n",
    "# создаем список с переменной MonthlyIncome\n",
    "income = ['MonthlyIncome']\n",
    "# создаем список с переменной DebtRatio\n",
    "debtratio = ['DebtRatio']\n",
    "# создаем список с переменной RevolvingUtilizationOfUnsecuredLines\n",
    "utilization = ['RevolvingUtilizationOfUnsecuredLines']\n",
    "# удаляем из списка количественных переменных переменные MonthlyIncome,\n",
    "# DebtRatio и RevolvingUtilizationOfUnsecuredLines\n",
    "num_columns = list(set(num_columns).difference(\n",
    "    set(numberofdependents + income + debtratio + utilization)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hwfEvpPaNwxq"
   },
   "outputs": [],
   "source": [
    "# создаем конвейер для количественных переменных\n",
    "num_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qqWBa4TlsxpW"
   },
   "outputs": [],
   "source": [
    "# создаем конвейер для переменной NumberOfDependents\n",
    "numberofdependents_pipe = Pipeline([\n",
    "    ('trans', NumberOfDependentsReplacer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4EjLJPIuNwxq"
   },
   "outputs": [],
   "source": [
    "# создаем конвейер для переменной MonthlyIncome\n",
    "income_pipe = Pipeline([\n",
    "    ('trans', MonthlyIncomeReplacer()),\n",
    "    ('imp', SimpleImputer(strategy='median')),\n",
    "    ('log', FunctionTransformer(np.log, validate=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "82o_rJF8Nwxr"
   },
   "outputs": [],
   "source": [
    "# создаем конвейер для переменной DebtRatio\n",
    "debtratio_pipe = Pipeline([\n",
    "    ('outl', OutlierRemover()),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jY0965HCNwxr"
   },
   "outputs": [],
   "source": [
    "# создаем конвейер для переменной DebtRatio\n",
    "debtratio_pipe2 = Pipeline([\n",
    "    ('outl', OutlierRemover()),\n",
    "    ('binn', CustomDiscretizer()),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oXyCVUl7Nwxs"
   },
   "outputs": [],
   "source": [
    "# создаем конвейер для переменной RevolvingUtilizationOfUnsecuredLines\n",
    "utilization_pipe = Pipeline([\n",
    "    ('trans', UtilizationThresholdSetter()),\n",
    "    ('imp', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "l_Iub7l8Nwxs"
   },
   "outputs": [],
   "source": [
    "# создаем конвейер для категориальных переменных\n",
    "cat_pipe = Pipeline([('ohe', OneHotEncoder(sparse=False, \n",
    "                                           handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rJOXK2rLNwxs"
   },
   "outputs": [],
   "source": [
    "# создаем список трехэлементных кортежей, в котором первый\n",
    "# элемент кортежа - название конвейера с преобразованиями\n",
    "transformers = [('num', num_pipe, num_columns),\n",
    "                ('numberofdependents', numberofdependents_pipe, numberofdependents),\n",
    "                ('income', income_pipe, income),\n",
    "                ('utilization', utilization_pipe, utilization),\n",
    "                ('debtratio', debtratio_pipe, debtratio),\n",
    "                ('debtratio2', debtratio_pipe2, debtratio),\n",
    "                ('cat', cat_pipe, cat_columns)]\n",
    "\n",
    "# передаем список трансформеров в ColumnTransformer\n",
    "transformer = ColumnTransformer(transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vU68FGtQNwxt"
   },
   "outputs": [],
   "source": [
    "# задаем итоговый конвейер\n",
    "pipe = Pipeline([('tf', transformer), \n",
    "                 ('logreg', LogisticRegression(C=0.03,\n",
    "                                               solver='liblinear', \n",
    "                                               random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "HlFgy-AGNwxt"
   },
   "outputs": [],
   "source": [
    "# задаем сетку гиперпараметров\n",
    "param_grid = {'tf__utilization__trans__threshold': [1.5, 1.75, 2],\n",
    "              'tf__numberofdependents__trans__replace_value': [0, 1, 2, 3],\n",
    "              'tf__debtratio2__binn__bins': [np.arange(0, 1.05, 0.05), \n",
    "                                             np.arange(0, 1.05, 0.1)],\n",
    "              'tf__income__trans__replace_value': [25000, 30000, 35000],\n",
    "              'tf__debtratio__outl__upper_quantile': [0.75, 0.8, 0.85]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PONjaHY5Nwxt"
   },
   "outputs": [],
   "source": [
    "# создаем экземпляр класса GridSearchCV, передав конвейер,\n",
    "# сетку гиперпараметров и указав количество\n",
    "# блоков перекрестной проверки\n",
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid, \n",
    "                  scoring='roc_auc',\n",
    "                  cv=5,\n",
    "                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wqhwVvm7Nwxu",
    "outputId": "1832b187-80cf-4ca5-cfb8-6fa5c70100f4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров: {'tf__debtratio2__binn__bins': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]), 'tf__debtratio__outl__upper_quantile': 0.8, 'tf__income__trans__replace_value': 35000, 'tf__numberofdependents__trans__replace_value': 3, 'tf__utilization__trans__threshold': 2}\n",
      "Наилучшее значение AUC-ROC: 0.863\n",
      "AUC-ROC на тестовом наборе: 0.864\n"
     ]
    }
   ],
   "source": [
    "# выполняем поиск по сетке\n",
    "gs.fit(train, y_train)\n",
    "# смотрим наилучшие значения гиперпараметров\n",
    "print('Наилучшие значения гиперпараметров: {}'.format(gs.best_params_))\n",
    "# смотрим наилучшее значение AUC-ROC\n",
    "print('Наилучшее значение AUC-ROC: {:.3f}'.format(gs.best_score_))\n",
    "# смотрим значение AUC-ROC на тестовой выборке\n",
    "print('AUC-ROC на тестовом наборе: {:.3f}'.format(\n",
    "    roc_auc_score(y_test, gs.predict_proba(test)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jAldb_csNwxu"
   },
   "outputs": [],
   "source": [
    "# записываем CSV-файл в объект DataFrame \n",
    "fulldata = pd.read_csv('Data/cs-training.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oIwFqLw3Nwxu"
   },
   "outputs": [],
   "source": [
    "# применяем функцию предварительной обработки \n",
    "# ко всем историческим данным\n",
    "fulldata = preprocessing(fulldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8atRZ6plNwxv"
   },
   "outputs": [],
   "source": [
    "# создаем массив меток и массив признаков\n",
    "y_fulldata = fulldata.pop('SeriousDlqin2yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUHKxEPnNwxv",
    "outputId": "6b1756e0-dd39-4ad9-ed4d-df57b97b07b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC на всей исторической выборке: 0.864\n"
     ]
    }
   ],
   "source": [
    "# записываем оптимальные значения гиперпараметров\n",
    "best_params = gs.best_params_\n",
    "# присваиваем итоговому конвейеру оптимальные \n",
    "# значения гиперпараметров\n",
    "pipe.set_params(**best_params)\n",
    "# обучаем итоговый конвейер с оптимальными значениями \n",
    "# гиперпараметров на всех исторических данных\n",
    "pipe.fit(fulldata, y_fulldata)\n",
    "# смотрим значение AUC-ROC\n",
    "print('AUC-ROC на всей исторической выборке: {:.3f}'.format(\n",
    "    roc_auc_score(y_fulldata, pipe.predict_proba(fulldata)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "44cy-e_ANwxv"
   },
   "outputs": [],
   "source": [
    "# записываем CSV-файл, содержащий новые данные,\n",
    "# в объект DataFrame\n",
    "newdata = pd.read_csv('Data/cs-test.csv', \n",
    "                      index_col=0)\n",
    "# записываем идентификатор набора новых данных\n",
    "test_id = newdata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "n9SQ_26sNwxw"
   },
   "outputs": [],
   "source": [
    "# выполняем предварительную обработку\n",
    "# новых данных\n",
    "newdata = preprocessing(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGn9GrH7Nwxw",
    "outputId": "a42c3f8b-8e11-48d0-b48a-ca091ce7a383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05477489, 0.05055286, 0.01712939, 0.09484548, 0.10469977])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# при помощью итогового конвейера с оптимальными значениями \n",
    "# гиперпараметров, обученного на всей исторической выборке, \n",
    "# вычисляем вероятности для новых данных\n",
    "prob = pipe.predict_proba(newdata)[:, 1]\n",
    "# выведем вероятности для первых 5 наблюдений\n",
    "prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XqqAHOQmNwxw"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Id': test_id, 'Probability': prob}).to_csv(\n",
    "    'subm_giveme.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
