{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обычный поиск оптимальных значений гиперпараметров моделей предварительной подготовки и модели машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки, функции и классы\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (train_test_split, \n",
    "                                     KFold, \n",
    "                                     ParameterGrid, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     RandomizedSearchCV)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (StandardScaler, \n",
    "                                   OneHotEncoder)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import WOEEncoder, SumEncoder\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Monthly Premium Auto</th>\n",
       "      <th>Months Since Last Claim</th>\n",
       "      <th>Months Since Policy Inception</th>\n",
       "      <th>Number of Open Complaints</th>\n",
       "      <th>Number of Policies</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2763.519279</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>56274.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>48767.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7645.861827</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2813.692575</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>43836.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer Lifetime Value Coverage Education EmploymentStatus Gender  \\\n",
       "0              2763.519279    Basic  Bachelor         Employed      F   \n",
       "1                      NaN      NaN  Bachelor       Unemployed      F   \n",
       "2                      NaN      NaN       NaN         Employed      F   \n",
       "3              7645.861827    Basic  Bachelor              NaN    NaN   \n",
       "4              2813.692575    Basic  Bachelor              NaN      M   \n",
       "\n",
       "    Income  Monthly Premium Auto  Months Since Last Claim  \\\n",
       "0  56274.0                   NaN                     32.0   \n",
       "1      0.0                   NaN                     13.0   \n",
       "2  48767.0                 108.0                      NaN   \n",
       "3      0.0                 106.0                     18.0   \n",
       "4  43836.0                  73.0                     12.0   \n",
       "\n",
       "   Months Since Policy Inception  Number of Open Complaints  \\\n",
       "0                            5.0                        NaN   \n",
       "1                           42.0                        NaN   \n",
       "2                           38.0                        0.0   \n",
       "3                            NaN                        NaN   \n",
       "4                            NaN                        NaN   \n",
       "\n",
       "   Number of Policies Response  \n",
       "0                 1.0       No  \n",
       "1                 NaN       No  \n",
       "2                 NaN       No  \n",
       "3                 7.0       No  \n",
       "4                 1.0       No  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# записываем CSV-файл в объект DataFrame\n",
    "data = pd.read_csv('Data/StateFarm_missing.csv', sep=';')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразовываем строковые значения в целочисленные\n",
    "dct = {'No': 0, 'Yes': 1}\n",
    "data['Response'] = data['Response'].replace(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем данные на обучающие и тестовые: получаем обучающий\n",
    "# массив признаков, тестовый массив признаков, обучающий массив\n",
    "# меток, тестовый массив меток\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Response', axis=1), \n",
    "    data['Response'], \n",
    "    test_size=0.3,\n",
    "    stratify=data['Response'],\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем списки категориальных\n",
    "# и количественных столбцов\n",
    "cat_columns = X_train.select_dtypes(\n",
    "    include='object').columns.tolist()\n",
    "num_columns = X_train.select_dtypes(\n",
    "    exclude='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем конвейер для количественных переменных\n",
    "num_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# создаем конвейер для категориальных переменных\n",
    "cat_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем список трехэлементных кортежей, в котором\n",
    "# первый элемент кортежа - название конвейера с\n",
    "# преобразованиями для определенного типа признаков\n",
    "transformers = [('num', num_pipe, num_columns), \n",
    "                ('cat', cat_pipe, cat_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# передаем список трансформеров в ColumnTransformer\n",
    "transformer = ColumnTransformer(transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем итоговый конвейер\n",
    "ml_pipe = Pipeline([\n",
    "    ('tf', transformer), \n",
    "    ('logreg', LogisticRegression(solver='lbfgs', \n",
    "                                  max_iter=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров:\n",
      "{'logreg__C': 0.01, 'tf__cat__imp__strategy': 'most_frequent', 'tf__num__imp__strategy': 'mean'}\n",
      "Наилучшее значение правильности: 0.900\n",
      "Значение правильности на тестовой выборке: 0.900\n"
     ]
    }
   ],
   "source": [
    "# задаем сетку гиперпараметров\n",
    "param_grid = {\n",
    "    'tf__num__imp__strategy': ['mean', 'median', 'constant'],    \n",
    "    'tf__cat__imp__strategy': ['most_frequent', 'constant'],\n",
    "    'logreg__C': [.01, .1, .5, 1, 5, 10, 100]\n",
    "}\n",
    "\n",
    "# создаем экземпляр класса GridSearchCV, передав \n",
    "# конвейер, сетку гиперпараметров и указав \n",
    "# количество блоков перекрестной проверки\n",
    "gs = GridSearchCV(ml_pipe, \n",
    "                  param_grid, \n",
    "                  cv=5)\n",
    "# выполняем поиск по всем значениям сетки\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# смотрим наилучшие значения гиперпараметров\n",
    "print(\"Наилучшие значения гиперпараметров:\\n{}\".format(\n",
    "    gs.best_params_))\n",
    "# смотрим наилучшее значение правильности\n",
    "print(\"Наилучшее значение правильности: {:.3f}\".format(\n",
    "    gs.best_score_))\n",
    "# смотрим значение правильности\n",
    "# на тестовой выборке\n",
    "print(\"Значение правильности на тестовой выборке: {:.3f}\".format(\n",
    "    gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем дамми-переменные, созданные классом OneHotEncoder\n",
    "cat = gs.best_estimator_['tf'].named_transformers_['cat']\n",
    "onehot_columns = list(cat.named_steps['ohe'].get_feature_names_out(\n",
    "    input_features=cat_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем к списку количественных переменных дамми-переменные,\n",
    "# созданные OneHotEncoder, т.е. сохраняем тот же порядок\n",
    "# столбцов, что задал ColumnTransformer\n",
    "all_cols = num_columns + onehot_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.978"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# извлекаем константу\n",
    "intercept = np.round(gs.best_estimator_['logreg'].intercept_[0], 3)\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.011,  0.014,  0.094, -0.038, -0.021, -0.026, -0.064, -0.041,\n",
       "         0.079, -0.038, -0.058,  0.039,  0.083, -0.074,  0.01 ,  0.053,\n",
       "        -0.215,  0.027,  0.53 , -0.395, -0.007,  0.007]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# извлекаем коэффициенты\n",
    "coef = np.round(gs.best_estimator_['logreg'].coef_, 3)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Константа: -1.978\n",
      "Регрессионные коэффициенты:\n",
      "Customer Lifetime Value 0.011\n",
      "Income 0.014\n",
      "Monthly Premium Auto 0.094\n",
      "Months Since Last Claim -0.038\n",
      "Months Since Policy Inception -0.021\n",
      "Number of Open Complaints -0.026\n",
      "Number of Policies -0.064\n",
      "Coverage_Basic -0.041\n",
      "Coverage_Extended 0.079\n",
      "Coverage_Premium -0.038\n",
      "Education_Bachelor -0.058\n",
      "Education_College 0.039\n",
      "Education_Doctor 0.083\n",
      "Education_High School or Below -0.074\n",
      "Education_Master 0.01\n",
      "EmploymentStatus_Disabled 0.053\n",
      "EmploymentStatus_Employed -0.215\n",
      "EmploymentStatus_Medical Leave 0.027\n",
      "EmploymentStatus_Retired 0.53\n",
      "EmploymentStatus_Unemployed -0.395\n",
      "Gender_F -0.007\n",
      "Gender_M 0.007\n"
     ]
    }
   ],
   "source": [
    "# печатаем название \"Константа\"    \n",
    "print(\"Константа:\", intercept)\n",
    "# печатаем название \"Регрессионные коэффициенты\"\n",
    "print(\"Регрессионные коэффициенты:\")\n",
    "# для удобства сопоставим каждому названию \n",
    "# предиктора соответствующий коэффициент\n",
    "for c, feature in zip(coef[0], all_cols):\n",
    "    print(feature, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           mean_test_score\n",
      "param_logreg__C param_tf__cat__imp__strategy param_tf__num__imp__strategy                 \n",
      "0.01            constant                     constant                             0.899742\n",
      "                                             mean                                 0.899742\n",
      "                                             median                               0.899742\n",
      "                most_frequent                constant                             0.899742\n",
      "                                             mean                                 0.899742\n",
      "                                             median                               0.899742\n",
      "0.10            constant                     constant                             0.899569\n",
      "                                             mean                                 0.899569\n",
      "                                             median                               0.899569\n",
      "                most_frequent                constant                             0.899569\n",
      "                                             mean                                 0.899569\n",
      "                                             median                               0.899569\n",
      "0.50            constant                     constant                             0.898363\n",
      "                                             mean                                 0.898363\n",
      "                                             median                               0.898363\n",
      "                most_frequent                constant                             0.898363\n",
      "                                             mean                                 0.898363\n",
      "                                             median                               0.898363\n",
      "1.00            constant                     constant                             0.898363\n",
      "                                             mean                                 0.898363\n",
      "                                             median                               0.898363\n",
      "                most_frequent                constant                             0.898363\n",
      "                                             mean                                 0.898363\n",
      "                                             median                               0.898363\n",
      "5.00            constant                     constant                             0.897847\n",
      "                                             mean                                 0.897502\n",
      "                                             median                               0.897502\n",
      "                most_frequent                constant                             0.897847\n",
      "                                             mean                                 0.897502\n",
      "                                             median                               0.897502\n",
      "10.00           constant                     constant                             0.898019\n",
      "                                             mean                                 0.897674\n",
      "                                             median                               0.897674\n",
      "                most_frequent                constant                             0.898019\n",
      "                                             mean                                 0.897674\n",
      "                                             median                               0.897674\n",
      "100.00          constant                     constant                             0.897847\n",
      "                                             mean                                 0.897847\n",
      "                                             median                               0.897847\n",
      "                most_frequent                constant                             0.897847\n",
      "                                             mean                                 0.897847\n",
      "                                             median                               0.897847\n"
     ]
    }
   ],
   "source": [
    "# запишем результаты поиска в DataFrame\n",
    "results = pd.DataFrame(gs.cv_results_)\n",
    "# превращаем в сводную таблицу\n",
    "table = results.pivot_table(\n",
    "    values=['mean_test_score'],    \n",
    "    index=['param_logreg__C', \n",
    "           'param_tf__cat__imp__strategy',\n",
    "           'param_tf__num__imp__strategy'])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обычный поиск оптимальных значений гиперпараметров моделей предварительной подготовки и модели машинного обучения с добавлением строки прогресса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняем поиск оптимальных значений гиперпараметров...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec93c0cb1824a808c42df04eb089d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Выполнено:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров:\n",
      "{'logreg__C': 0.01, 'tf__cat__imp__strategy': 'most_frequent', 'tf__num__imp__strategy': 'mean'}\n",
      "Наилучшее значение accuracy: 0.900\n",
      "Значение accuracy на тестовой выборке: 0.900\n"
     ]
    }
   ],
   "source": [
    "# создаем пустой список scores, в который будем записывать\n",
    "# гиперпараметры и полученные метрики качества\n",
    "scores = []\n",
    "\n",
    "# задаем метрику качества\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# печатаем строку статуса\n",
    "print(\"Выполняем поиск оптимальных значений гиперпараметров...\")\n",
    "\n",
    "# поскольку tqdm работает с итерируемыми объектами, \n",
    "# то используем класс ParameterGrid для того, чтобы \n",
    "# в явном виде перебирать гипермараметры внутри цикла for\n",
    "for param in tqdm(list(ParameterGrid(param_grid)), \n",
    "                  desc='Выполнено'):\n",
    "    # задаем гиперпараметры конвейера\n",
    "    ml_pipe.set_params(**param)\n",
    "    \n",
    "    # обучаем конвейер с этими гиперпараметрами \n",
    "    # и сохраняем гиперпараметры и полученные \n",
    "    # метрики качества в список scores\n",
    "    scores.append([param, cross_val_score(ml_pipe,\n",
    "                                          X_train,\n",
    "                                          y_train,\n",
    "                                          scoring=scoring,\n",
    "                                          cv=5)])\n",
    "    \n",
    "    # рассчитываем и добавляем в список scores \n",
    "    # усредненную метрику качества\n",
    "    scores[-1].append(sum(scores[-1][1]) / len(scores[-1][1]))\n",
    "\n",
    "# сортируем список с полученными результатами\n",
    "scores.sort(reverse=True, key=lambda x: x[2])\n",
    "\n",
    "# сохраняем и печатаем наилучшие значения гиперпараметров\n",
    "best_params = scores[0][0]\n",
    "print(\"Наилучшие значения гиперпараметров:\", \n",
    "      best_params, sep='\\n', end='\\n')\n",
    "\n",
    "# сохраняем и печатаем наилучшее значение метрики качества\n",
    "best_score = scores[0][2]\n",
    "print(\"Наилучшее значение %s: %.3f\" % (scoring, best_score))\n",
    "\n",
    "# передаем наилучшие значения гиперпараметров \n",
    "# в конвейер и обучаем его с этими значениями\n",
    "# гиперпараметров на всей обучающей выборке\n",
    "ml_pipe.set_params(**best_params).fit(X_train, y_train)\n",
    "# вычисляем правильность для тестовой выборки\n",
    "test_score = ml_pipe.score(X_test, y_test)\n",
    "# печатаем значение метрики качества на тестовой выборке\n",
    "print(\"Значение %s на тестовой выборке: %.3f\" % (scoring, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный поиск оптимальных значений гиперпараметров моделей предварительной подготовки и модели машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров:\n",
      "{'tf__num__imp__strategy': 'median', 'tf__cat__imp__strategy': 'constant', 'logreg__C': 0.01}\n",
      "Наилучшее значение правильности: 0.900\n",
      "Значение правильности на тестовой выборке: 0.900\n"
     ]
    }
   ],
   "source": [
    "# создаем экземпляр класса RandomizedSearchCV, передав конвейер,\n",
    "# сетку гиперпараметров и указав количество блоков перекрестной \n",
    "# проверки, количество отбираемых значений гиперпараметров, \n",
    "# задав стартовое значение генератора псевдослучайных чисел для \n",
    "# воспроизводимости результатов\n",
    "rs = RandomizedSearchCV(ml_pipe, \n",
    "                        param_grid,\n",
    "                        n_iter=10,\n",
    "                        cv=5,\n",
    "                        random_state=42,\n",
    "                        return_train_score=False)\n",
    "# выполняем поиск по случайно \n",
    "# отобранным значениям из сетки\n",
    "rs.fit(X_train, y_train)\n",
    "# смотрим наилучшие значения гиперпараметров\n",
    "print(\"Наилучшие значения гиперпараметров:\\n{}\".format(\n",
    "    rs.best_params_))\n",
    "# смотрим наилучшее значение правильности\n",
    "print(\"Наилучшее значение правильности: {:.3f}\".format(\n",
    "    rs.best_score_))\n",
    "# смотрим значение правильности\n",
    "# на тестовой выборке\n",
    "print(\"Значение правильности на тестовой выборке: {:.3f}\".format(\n",
    "    rs.score(X_test, y_test)))                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           mean_test_score\n",
      "param_logreg__C param_tf__cat__imp__strategy param_tf__num__imp__strategy                 \n",
      "0.01            constant                     median                               0.899742\n",
      "0.10            most_frequent                constant                             0.899569\n",
      "                                             mean                                 0.899569\n",
      "0.50            most_frequent                median                               0.898363\n",
      "1.00            most_frequent                median                               0.898363\n",
      "5.00            constant                     constant                             0.897847\n",
      "                most_frequent                constant                             0.897847\n",
      "                                             median                               0.897502\n",
      "10.00           most_frequent                mean                                 0.897674\n",
      "100.00          constant                     mean                                 0.897847\n"
     ]
    }
   ],
   "source": [
    "# запишем результаты поиска в DataFrame\n",
    "res = pd.DataFrame(rs.cv_results_)\n",
    "# превращаем в сводную таблицу\n",
    "tbl = res.pivot_table(\n",
    "    values=['mean_test_score'],    \n",
    "    index=['param_logreg__C', \n",
    "           'param_tf__cat__imp__strategy',\n",
    "           'param_tf__num__imp__strategy'])\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обычный поиск оптимальных значений гиперпараметров для CatBoost при обработке категориальных признаков \"как есть\" ( заданы индексы категориальных признаков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем конвейер для категориальных переменных,\n",
    "# который будем использовать с catboost\n",
    "catbst_cat_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# создаем конвейер для количественных переменных,\n",
    "# который будем использовать с catboost\n",
    "catbst_num_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем список трехэлементных кортежей, в котором\n",
    "# первый элемент кортежа - название конвейера с\n",
    "# преобразованиями для определенного типа признаков\n",
    "catbst_transformers = [('cat', catbst_cat_pipe, cat_columns),\n",
    "                       ('num', catbst_num_pipe, num_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('cat',\n",
       "                                 Pipeline(steps=[('imp',\n",
       "                                                  SimpleImputer(strategy='most_frequent'))]),\n",
       "                                 ['Coverage', 'Education', 'EmploymentStatus',\n",
       "                                  'Gender']),\n",
       "                                ('num',\n",
       "                                 Pipeline(steps=[('imp',\n",
       "                                                  SimpleImputer(strategy='median'))]),\n",
       "                                 ['Customer Lifetime Value', 'Income',\n",
       "                                  'Monthly Premium Auto',\n",
       "                                  'Months Since Last Claim',\n",
       "                                  'Months Since Policy Inception',\n",
       "                                  'Number of Open Complaints',\n",
       "                                  'Number of Policies'])])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# передаем список трансформеров в ColumnTransformer\n",
    "catbst_transformer = ColumnTransformer(\n",
    "    transformers=catbst_transformers)\n",
    "# взглянем на объект\n",
    "catbst_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Customer Lifetime Value', 'Coverage', 'Education', 'EmploymentStatus', 'Gender', 'Income', 'Monthly Premium Auto', 'Months Since Last Claim', 'Months Since Policy Inception', 'Number of Open Complaints', 'Number of Policies', 'Response']\n"
     ]
    }
   ],
   "source": [
    "# взглянем на исходный список столбцов\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# записываем индексы категориальных признаков\n",
    "# в пространстве трансформированных признаков\n",
    "cat_feat_ind = [col for col in range(len(cat_columns))]\n",
    "cat_feat_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем экземпляр класса CatBoostClassifier\n",
    "catbst = CatBoostClassifier(n_estimators=200,\n",
    "                            logging_level='Silent',\n",
    "                            random_state=42,\n",
    "                            cat_features=cat_feat_ind)\n",
    "\n",
    "# задаем итоговый конвейер\n",
    "catbst_pipe = Pipeline([('tf', catbst_transformer), \n",
    "                        ('catbst', catbst)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров:\n",
      "{'catbst__max_depth': 8, 'tf__cat__imp__strategy': 'constant'}\n",
      "Наилучшее значение правильности: 0.918\n",
      "Значение правильности на тестовой выборке: 0.924\n"
     ]
    }
   ],
   "source": [
    "# задаем сетку гиперпараметров\n",
    "catbst_param_grid = {\n",
    "    'tf__cat__imp__strategy': ['most_frequent', 'constant'],\n",
    "    'catbst__max_depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# создаем экземпляр класса GridSearchCV, передав конвейер,\n",
    "# сетку гиперпараметров и указав количество\n",
    "# блоков перекрестной проверки\n",
    "catbst_gs = GridSearchCV(catbst_pipe, \n",
    "                         catbst_param_grid, \n",
    "                         cv=5)\n",
    "# выполняем поиск по всем значениям сетки\n",
    "catbst_gs.fit(X_train, y_train)\n",
    "\n",
    "# смотрим наилучшие значения гиперпараметров\n",
    "print(\"Наилучшие значения гиперпараметров:\\n{}\".format(\n",
    "    catbst_gs.best_params_))\n",
    "# смотрим наилучшее значение правильности\n",
    "print(\"Наилучшее значение правильности: {:.3f}\".format(\n",
    "    catbst_gs.best_score_))\n",
    "# смотрим значение правильности на тестовой выборке\n",
    "print(\"Значение правильности на тестовой выборке: {:.3f}\".format(\n",
    "    catbst_gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      mean_test_score\n",
      "param_catbst__max_depth param_tf__cat__imp__strategy                 \n",
      "4                       constant                             0.903015\n",
      "                        most_frequent                        0.903359\n",
      "6                       constant                             0.908183\n",
      "                        most_frequent                        0.907666\n",
      "8                       constant                             0.917657\n",
      "                        most_frequent                        0.916968\n"
     ]
    }
   ],
   "source": [
    "# запишем результаты поиска в DataFrame\n",
    "results = pd.DataFrame(catbst_gs.cv_results_)\n",
    "# превращаем в сводную таблицу\n",
    "table = results.pivot_table(\n",
    "    values=['mean_test_score'],    \n",
    "    index=['param_catbst__max_depth', \n",
    "           'param_tf__cat__imp__strategy'])\n",
    "# печатаем таблицу\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор оптимальной модели предварительной подготовки данных в рамках отдельного трансформера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем конвейер для количественных переменных\n",
    "num_pipe2 = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# создаем конвейер для категориальных переменных\n",
    "cat_pipe2 = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "    ('woe', WOEEncoder(return_df=False)),\n",
    "    ('sum', SumEncoder(return_df=False)),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# создаем список трехэлементных кортежей, в котором\n",
    "# первый элемент кортежа - название конвейера с\n",
    "# преобразованиями для определенного типа признаков\n",
    "transformers2 = [('num2', num_pipe2, num_columns),\n",
    "                 ('cat2', cat_pipe2, cat_columns)]\n",
    "\n",
    "# передаем список трансформеров в ColumnTransformer\n",
    "transformer2 = ColumnTransformer(transformers=transformers2)\n",
    "\n",
    "# задаем итоговый конвейер\n",
    "ml_pipe2 = Pipeline([\n",
    "    ('tf2', transformer2), \n",
    "    ('boost', GradientBoostingClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем сетку гиперпараметров\n",
    "param_grid2 = [\n",
    "    {'boost__max_depth': [4, 6, 8],\n",
    "     'tf2__cat2__ohe': [None],\n",
    "     'tf2__cat2__sum': [None]},\n",
    "    {'boost__max_depth': [4, 6, 8],\n",
    "     'tf2__cat2__woe': [None],\n",
    "     'tf2__cat2__sum': [None]},\n",
    "    {'boost__max_depth': [4, 6, 8],\n",
    "     'tf2__cat2__woe': [None],\n",
    "     'tf2__cat2__ohe': [None]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/artemgruzdev/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров:\n",
      "{'boost__max_depth': 8, 'tf2__cat2__ohe': None, 'tf2__cat2__sum': None}\n",
      "Наилучшее значение правильности: 0.932\n",
      "Значение правильности на тестовой выборке: 0.939\n"
     ]
    }
   ],
   "source": [
    "# создаем экземпляр класса GridSearchCV, передав конвейер,\n",
    "# сетку гиперпараметров, оптимизируемую метрику, указав\n",
    "# стратегию перекрестной проверки\n",
    "gs2 = GridSearchCV(ml_pipe2, \n",
    "                   param_grid2, \n",
    "                   cv=5)\n",
    "# выполняем поиск по всем значениям сетки\n",
    "gs2.fit(X_train, y_train)\n",
    "# смотрим наилучшие значения гиперпараметров\n",
    "print(\"Наилучшие значения гиперпараметров:\\n{}\".format(\n",
    "    gs2.best_params_))\n",
    "# смотрим наилучшее значение правильности\n",
    "print(\"Наилучшее значение правильности: {:.3f}\".format(\n",
    "    gs2.best_score_))\n",
    "# смотрим значение правильности\n",
    "# на тестовой выборке\n",
    "print(\"Значение правильности на тестовой выборке: {:.3f}\".format(\n",
    "    gs2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_boost__max_depth</th>\n",
       "      <th>param_boost__encoding</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>{'boost__max_depth': 8, 'tf2__cat2__ohe': None, 'tf2__cat2__sum': None}</td>\n",
       "      <td>0.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>{'boost__max_depth': 8, 'tf2__cat2__ohe': None, 'tf2__cat2__woe': None}</td>\n",
       "      <td>0.929371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>{'boost__max_depth': 8, 'tf2__cat2__sum': None, 'tf2__cat2__woe': None}</td>\n",
       "      <td>0.929199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>{'boost__max_depth': 6, 'tf2__cat2__ohe': None, 'tf2__cat2__sum': None}</td>\n",
       "      <td>0.921792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>{'boost__max_depth': 6, 'tf2__cat2__ohe': None, 'tf2__cat2__woe': None}</td>\n",
       "      <td>0.919552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>{'boost__max_depth': 6, 'tf2__cat2__sum': None, 'tf2__cat2__woe': None}</td>\n",
       "      <td>0.918691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{'boost__max_depth': 4, 'tf2__cat2__sum': None, 'tf2__cat2__woe': None}</td>\n",
       "      <td>0.906115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>{'boost__max_depth': 4, 'tf2__cat2__ohe': None, 'tf2__cat2__woe': None}</td>\n",
       "      <td>0.905943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>{'boost__max_depth': 4, 'tf2__cat2__ohe': None, 'tf2__cat2__sum': None}</td>\n",
       "      <td>0.905599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_boost__max_depth  \\\n",
       "2                      8   \n",
       "8                      8   \n",
       "5                      8   \n",
       "1                      6   \n",
       "7                      6   \n",
       "4                      6   \n",
       "3                      4   \n",
       "6                      4   \n",
       "0                      4   \n",
       "\n",
       "                                                     param_boost__encoding  \\\n",
       "2  {'boost__max_depth': 8, 'tf2__cat2__ohe': None, 'tf2__cat2__sum': None}   \n",
       "8  {'boost__max_depth': 8, 'tf2__cat2__ohe': None, 'tf2__cat2__woe': None}   \n",
       "5  {'boost__max_depth': 8, 'tf2__cat2__sum': None, 'tf2__cat2__woe': None}   \n",
       "1  {'boost__max_depth': 6, 'tf2__cat2__ohe': None, 'tf2__cat2__sum': None}   \n",
       "7  {'boost__max_depth': 6, 'tf2__cat2__ohe': None, 'tf2__cat2__woe': None}   \n",
       "4  {'boost__max_depth': 6, 'tf2__cat2__sum': None, 'tf2__cat2__woe': None}   \n",
       "3  {'boost__max_depth': 4, 'tf2__cat2__sum': None, 'tf2__cat2__woe': None}   \n",
       "6  {'boost__max_depth': 4, 'tf2__cat2__ohe': None, 'tf2__cat2__woe': None}   \n",
       "0  {'boost__max_depth': 4, 'tf2__cat2__ohe': None, 'tf2__cat2__sum': None}   \n",
       "\n",
       "   mean_test_score  \n",
       "2         0.932300  \n",
       "8         0.929371  \n",
       "5         0.929199  \n",
       "1         0.921792  \n",
       "7         0.919552  \n",
       "4         0.918691  \n",
       "3         0.906115  \n",
       "6         0.905943  \n",
       "0         0.905599  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# увеличиваем ширину столбцов\n",
    "pd.set_option('max_colwidth', 100)\n",
    "# записываем результаты перекрестной \n",
    "# проверки в DataFrame\n",
    "results2 = pd.DataFrame(gs2.cv_results_)\n",
    "# отбираем нужные столбцы\n",
    "table2 = results2.loc[:, ['param_boost__max_depth', \n",
    "                          'params', \n",
    "                          'mean_test_score']]\n",
    "# переименуем столбец для удобства интерпретации\n",
    "table2.rename(columns={'params': 'param_boost__encoding'}, \n",
    "              inplace=True)\n",
    "# сортируем по убыванию\n",
    "table2.sort_values('mean_test_score', \n",
    "                   ascending=False, \n",
    "                   inplace=True)\n",
    "table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_boost__max_depth</th>\n",
       "      <th>param_boost__encoding</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>woe</td>\n",
       "      <td>0.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ohe</td>\n",
       "      <td>0.929371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.929199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>woe</td>\n",
       "      <td>0.921792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.919552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>ohe</td>\n",
       "      <td>0.918691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ohe</td>\n",
       "      <td>0.906115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.905943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>woe</td>\n",
       "      <td>0.905599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_boost__max_depth param_boost__encoding  mean_test_score\n",
       "2                      8                   woe         0.932300\n",
       "8                      8                   ohe         0.929371\n",
       "5                      8                   sum         0.929199\n",
       "1                      6                   woe         0.921792\n",
       "7                      6                   sum         0.919552\n",
       "4                      6                   ohe         0.918691\n",
       "3                      4                   ohe         0.906115\n",
       "6                      4                   sum         0.905943\n",
       "0                      4                   woe         0.905599"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаем серию со значением кодировок, не забывая передать \n",
    "# индекс датафрейма для верного сопоставления\n",
    "enc = pd.Series(['woe', 'ohe', 'sum',\n",
    "                 'woe', 'sum', 'ohe',\n",
    "                 'ohe', 'sum', 'woe'],\n",
    "                 index = table2.index)\n",
    "# создаем копию таблицы\n",
    "table2_copy = table2.copy()\n",
    "# значения серии становятся значениями \n",
    "# переименованного столбца\n",
    "table2_copy['param_boost__encoding'] = enc\n",
    "table2_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_boost__max_depth</th>\n",
       "      <th>param_boost__encoding</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>woe</td>\n",
       "      <td>0.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.929371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>ohe</td>\n",
       "      <td>0.929199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>woe</td>\n",
       "      <td>0.921792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.919552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>ohe</td>\n",
       "      <td>0.918691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ohe</td>\n",
       "      <td>0.906115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.905943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>woe</td>\n",
       "      <td>0.905599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_boost__max_depth param_boost__encoding  mean_test_score\n",
       "2                      8                   woe         0.932300\n",
       "8                      8                   sum         0.929371\n",
       "5                      8                   ohe         0.929199\n",
       "1                      6                   woe         0.921792\n",
       "7                      6                   sum         0.919552\n",
       "4                      6                   ohe         0.918691\n",
       "3                      4                   ohe         0.906115\n",
       "6                      4                   sum         0.905943\n",
       "0                      4                   woe         0.905599"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# присваиваем кодировки автоматически в зависимости от того, \n",
    "# какие логические условия у нас выполняются\n",
    "cond = (table2['param_boost__encoding'].str.contains(\n",
    "    'tf2__cat2__ohe', regex=False)) & (\n",
    "    table2['param_boost__encoding'].str.contains(\n",
    "        'tf2__cat2__sum', regex=False))\n",
    "cond2 = (table2['param_boost__encoding'].str.contains(\n",
    "    'tf2__cat2__ohe', regex=False)) & (\n",
    "    table2['param_boost__encoding'].str.contains(\n",
    "        'tf2__cat2__woe', regex=False))\n",
    "cond3 = (table2['param_boost__encoding'].str.contains(\n",
    "    'tf2__cat2__woe', regex=False)) & (\n",
    "    table2['param_boost__encoding'].str.contains(\n",
    "        'tf2__cat2__sum', regex=False))\n",
    "\n",
    "table2['param_boost__encoding'] = np.where(\n",
    "    cond, 'woe', (np.where(cond2, 'sum', 'ohe')))\n",
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор оптимального метода машинного обучения среди разных методов машинного обучения (перебор значений гиперпараметров  с отдельной предобработкой данных под каждый метод машинного обучения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mortgage</th>\n",
       "      <th>life_ins</th>\n",
       "      <th>cre_card</th>\n",
       "      <th>deb_card</th>\n",
       "      <th>mob_bank</th>\n",
       "      <th>curr_acc</th>\n",
       "      <th>internet</th>\n",
       "      <th>perloan</th>\n",
       "      <th>savings</th>\n",
       "      <th>atm_user</th>\n",
       "      <th>markpl</th>\n",
       "      <th>age</th>\n",
       "      <th>cus_leng</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>18.0</td>\n",
       "      <td>less than 3 years</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from 3 to 7 years</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18.0</td>\n",
       "      <td>from 3 to 7 years</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mortgage life_ins cre_card deb_card mob_bank curr_acc internet perloan  \\\n",
       "0       No       No       No       No       No       No       No      No   \n",
       "1      Yes      Yes      NaN      NaN      Yes       No      NaN     NaN   \n",
       "2      Yes      Yes      NaN      Yes       No       No       No      No   \n",
       "3      Yes      Yes      Yes      Yes      NaN      Yes       No      No   \n",
       "4      Yes      Yes       No      Yes       No       No       No     Yes   \n",
       "\n",
       "  savings atm_user markpl   age           cus_leng response  \n",
       "0      No       No     No  18.0  less than 3 years       No  \n",
       "1     NaN      Yes     No  18.0                NaN      Yes  \n",
       "2      No       No    Yes   NaN  from 3 to 7 years      Yes  \n",
       "3      No      NaN    Yes  18.0  from 3 to 7 years      Yes  \n",
       "4      No      Yes     No   NaN                NaN       No  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# записываем CSV-файл в объект DataFrame\n",
    "data = pd.read_csv('Data/Response.csv', sep=';')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем обучающий массив признаков, обучающий массив меток,\n",
    "# тестовый массив признаков, тестовый массив меток\n",
    "tr, tst, y_tr, y_tst = train_test_split(\n",
    "    data.drop('response', axis=1), \n",
    "    data['response'], \n",
    "    test_size=.3, \n",
    "    stratify=data['response'], \n",
    "    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем списки категориальных\n",
    "# и количественных столбцов\n",
    "categorical_features = tr.select_dtypes(\n",
    "    include='object').columns.tolist()\n",
    "numeric_features = tr.select_dtypes(\n",
    "    exclude='object').columns.tolist()\n",
    "\n",
    "# создаем трансформеры\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(sparse=False, \n",
    "                             handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# передаем список трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# формируем итоговый конвейер\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs', \n",
    "                                      max_iter=400))\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем сетку гиперпараметров\n",
    "param_grid = [\n",
    "    {'classifier': [GradientBoostingClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42,\n",
    "        subsample=0.8)],\n",
    "     'classifier__max_depth': [4, 6, 8],\n",
    "     'preprocessor__num__scaler': [None]},\n",
    "    {'classifier': [LogisticRegression(solver='lbfgs', \n",
    "                                       max_iter=400)],\n",
    "     'classifier__C': [.05, .01], \n",
    "     'preprocessor__num__scaler': [None]},\n",
    "    {'classifier': [LogisticRegression(solver='lbfgs', \n",
    "                                       max_iter=400)],\n",
    "     'classifier__C': [.05, .01]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров:\n",
      "{'classifier': GradientBoostingClassifier(max_depth=4, n_estimators=50, random_state=42,\n",
      "                           subsample=0.8), 'classifier__max_depth': 4, 'preprocessor__num__scaler': None}\n",
      "Наилучшее значение AUC-ROC: 0.910\n",
      "AUC-ROC на тестовой выборке: 0.907\n"
     ]
    }
   ],
   "source": [
    "# создаем экземпляр класса KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "# создаем экземпляр класса GridSearchCV, передав конвейер,\n",
    "# сетку гиперпараметров, оптимизируемую метрику, указав\n",
    "# стратегию перекрестной проверки\n",
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid, \n",
    "                  scoring='roc_auc', \n",
    "                  cv=kf)\n",
    "# выполняем поиск по всем значениям сетки\n",
    "gs.fit(tr, y_tr)\n",
    "# смотрим наилучшие значения гиперпараметров\n",
    "print(\"Наилучшие значения гиперпараметров:\\n{}\".format(\n",
    "    gs.best_params_))\n",
    "# смотрим наилучшее значение AUC\n",
    "print(\"Наилучшее значение AUC-ROC: {:.3f}\".format(\n",
    "    gs.best_score_))\n",
    "# смотрим значение AUC на тестовой выборке\n",
    "print(\"AUC-ROC на тестовой выборке: {:.3f}\".format(\n",
    "    roc_auc_score(y_tst, gs.predict_proba(tst)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем трансформеры для логистической регрессии\n",
    "numeric_transformer_logreg = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_logreg = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(sparse=False, \n",
    "                             handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# передаем список трансформеров для логистической \n",
    "# регрессии в ColumnTransformer\n",
    "preprocessor_logreg = ColumnTransformer([\n",
    "    ('num', numeric_transformer_logreg, numeric_features),\n",
    "    ('cat', categorical_transformer_logreg, categorical_features)\n",
    "])\n",
    "\n",
    "# формируем итоговый конвейер для логистической регрессии\n",
    "pipe_logreg = Pipeline([\n",
    "    ('preprocessor', preprocessor_logreg),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs', \n",
    "                                      max_iter=400))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем трансформеры для градиентного бустинга\n",
    "numeric_transformer_boost = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', \n",
    "                              fill_value=-9999))\n",
    "])\n",
    "\n",
    "categorical_transformer_boost = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('sum', SumEncoder(return_df=False))\n",
    "])\n",
    "\n",
    "# передаем список трансформеров для градиентного \n",
    "# бустинга в ColumnTransformer\n",
    "preprocessor_boost = ColumnTransformer([\n",
    "    ('num', numeric_transformer_boost, numeric_features),\n",
    "    ('cat', categorical_transformer_boost, categorical_features)\n",
    "])\n",
    "\n",
    "# формируем итоговый конвейер для градиентного бустинга\n",
    "pipe_boost = Pipeline([\n",
    "    ('preprocessor', preprocessor_boost),\n",
    "    ('classifier', GradientBoostingClassifier(\n",
    "        random_state=42, subsample=0.8))\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем сетки значений гиперпараметров\n",
    "param_logreg_scaled = [{'classifier__C': [.05, .01]}] \n",
    "param_logreg_non_scaled = [{'classifier__C': [.05, .01], \n",
    "                            'preprocessor__num__scaler': [None]}] \n",
    "param_boost = [{'classifier__max_depth': [2, 4], \n",
    "                'classifier__n_estimators': [50, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем экземпляры класса GridSearchCV\n",
    "gs_logreg_scaled = GridSearchCV(\n",
    "    pipe_logreg, \n",
    "    param_logreg_scaled, \n",
    "    scoring='roc_auc', \n",
    "    cv=5)\n",
    "\n",
    "gs_boost = GridSearchCV(\n",
    "    pipe_boost, \n",
    "    param_boost, \n",
    "    scoring='roc_auc', \n",
    "    cv=5)\n",
    "\n",
    "gs_logreg_non_scaled = GridSearchCV(\n",
    "    pipe_logreg,\n",
    "    param_logreg_non_scaled, \n",
    "    scoring='roc_auc', \n",
    "    cv=5)\n",
    "\n",
    "# объединяем в список\n",
    "grids = [gs_logreg_scaled, gs_boost, gs_logreg_non_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем словарь для сопоставления индекса\n",
    "# с названием метода машинного обучения\n",
    "grid_dict = {0: 'Логистическая регрессия со стандартизацией', \n",
    "             1: 'Градиентный бустинг',\n",
    "             2: 'Логистическая регрессия без стандартизации'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняем поиск оптимальных значений гиперпараметров...\n",
      "\n",
      "Метод: Логистическая регрессия со стандартизацией\n",
      "Наилучшие значения гиперпараметров: {'classifier__C': 0.05}\n",
      "Наилучшее значение AUC-ROC: 0.905\n",
      "\n",
      "Метод: Градиентный бустинг\n",
      "Наилучшие значения гиперпараметров: {'classifier__max_depth': 4, 'classifier__n_estimators': 50}\n",
      "Наилучшее значение AUC-ROC: 0.909\n",
      "\n",
      "Метод: Логистическая регрессия без стандартизации\n",
      "Наилучшие значения гиперпараметров: {'classifier__C': 0.05, 'preprocessor__num__scaler': None}\n",
      "Наилучшее значение AUC-ROC: 0.905\n",
      "\n",
      "\n",
      "Лучший метод машинного обучения: Градиентный бустинг\n",
      "Значения гиперпараметров лучшего метода: {'classifier__max_depth': 4, 'classifier__n_estimators': 50}\n",
      "AUC-ROC лучшего метода на тестовой выборке: 0.907\n"
     ]
    }
   ],
   "source": [
    "# отключим предупреждения касательно поведения в будущем\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# печатаем строку статуса\n",
    "print(\"Выполняем поиск оптимальных значений гиперпараметров...\")\n",
    "# добавляем пустую строку в вывод\n",
    "print(\"\")\n",
    "# создаем пустой список, в который будем записывать наилучшее \n",
    "# значение AUC по каждому методу машинного обучения\n",
    "auc_list = []\n",
    "# здесь будем хранить индекс, соответствующий \n",
    "# методу машинного обучения\n",
    "best_clf = 0\n",
    "# выполняем поиск по сетке\n",
    "for idx, gs in enumerate(grids):\n",
    "    # печатаем метод машинного обучения\n",
    "    print(\"Метод: %s\" % grid_dict[idx])\n",
    "    gs.fit(tr, y_tr)\n",
    "    # печатаем наилучшие значения гиперпараметров для этого метода\n",
    "    print(\"Наилучшие значения гиперпараметров: %s\" % gs.best_params_)\n",
    "    # печатаем наилучшее значение AUC для этого метода\n",
    "    print(\"Наилучшее значение AUC-ROC: %.3f\" % gs.best_score_)\n",
    "    # добавляем пустую строку в вывод\n",
    "    print(\"\")\n",
    "    # записываем наилучшее значение AUC для метода машинного обучения\n",
    "    auc_score = gs.best_score_\n",
    "    # добавляем наилучшее значение AUC в список\n",
    "    auc_list.append(auc_score)\n",
    "    # если мы получаем максимальное значение AUC\n",
    "    if auc_score == max(auc_list):\n",
    "        # записываем индекс наилучшего метода\n",
    "        best_clf = idx\n",
    "        # записываем значения гиперпараметров наилучшего метода\n",
    "        bst_params = gs.best_params_\n",
    "        # вычисляем вероятности положительного класса\n",
    "        proba_tst = gs.predict_proba(tst)[:, 1]\n",
    "        # вычисляем AUC на тестовой выборке\n",
    "        auc_tst = roc_auc_score(y_tst, proba_tst)\n",
    "# добавляем пустую строку в вывод\n",
    "print(\"\")\n",
    "# печатаем название лучшего метода, используем словарь\n",
    "# для сопоставления индекса с названием  метода\n",
    "# машинного обучения\n",
    "print(\"Лучший метод машинного обучения: %s\" % grid_dict[best_clf])\n",
    "# печатаем значения гиперпараметров лучшего метода\n",
    "print(\"Значения гиперпараметров лучшего метода: %s\" % bst_params)\n",
    "# печатаем AUC лучшего метода на тестовой выборке\n",
    "print(\"AUC-ROC лучшего метода на тестовой выборке: %.3f\" % auc_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a92f040e4be408b8fd5b31a896a3f32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_824b0fd9b60c487da0db9d8313fb86f5",
       "style": "IPY_MODEL_8f02172b921b444590f24355799cec18",
       "value": " 42/42 [00:13&lt;00:00,  3.21it/s]"
      }
     },
     "1690a6bdcc4e4e81adabe2313451521a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6aa146b942924850ab2ee3b00a7140e6",
        "IPY_MODEL_0a92f040e4be408b8fd5b31a896a3f32"
       ],
       "layout": "IPY_MODEL_f55b02be46f94f74a838a666cbcbccd2"
      }
     },
     "4085a7858e544d4b92453ed0875b6cbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45ba292abfe742579422c7ed719a37d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5ba58812d3874a0fa3e6974405ba3e33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "608859bddebf4641956488ff4e662e32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_be97f634be6b4ac6b35ded50541dcf63",
        "IPY_MODEL_fb1039c8b81b48cfac5d8d03ba9dbaea"
       ],
       "layout": "IPY_MODEL_5ba58812d3874a0fa3e6974405ba3e33"
      }
     },
     "647e1e8fc7fb41b9a3c1b9bc5d566046": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6aa146b942924850ab2ee3b00a7140e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Выполнено: 100%",
       "layout": "IPY_MODEL_647e1e8fc7fb41b9a3c1b9bc5d566046",
       "max": 42,
       "style": "IPY_MODEL_d2e5970908484359977b4fa5a73159f4",
       "value": 42
      }
     },
     "824b0fd9b60c487da0db9d8313fb86f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8f02172b921b444590f24355799cec18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "be97f634be6b4ac6b35ded50541dcf63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Выполнено: 100%",
       "layout": "IPY_MODEL_4085a7858e544d4b92453ed0875b6cbe",
       "max": 42,
       "style": "IPY_MODEL_e42df6d7c8614d4c909b18e1e4472c04",
       "value": 42
      }
     },
     "d2e5970908484359977b4fa5a73159f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "dff669f3f1d84fe58bbd29843aaa5003": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e42df6d7c8614d4c909b18e1e4472c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "f55b02be46f94f74a838a666cbcbccd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb1039c8b81b48cfac5d8d03ba9dbaea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_45ba292abfe742579422c7ed719a37d1",
       "style": "IPY_MODEL_dff669f3f1d84fe58bbd29843aaa5003",
       "value": " 42/42 [00:10&lt;00:00,  4.00it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
