{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки, классы и функции\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.multiclass import (OneVsRestClassifier, \n",
    "                                OneVsOneClassifier,\n",
    "                                OutputCodeClassifier)\n",
    "from sklearn.preprocessing import (StandardScaler,\n",
    "                                   LabelEncoder)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import (clone,\n",
    "                          MetaEstimatorMixin, \n",
    "                          ClassifierMixin, \n",
    "                          BaseEstimator)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.metaestimators import _safe_split\n",
    "from sklearn.metrics import (roc_auc_score, \n",
    "                             pairwise_distances)\n",
    "from sklearn.utils.fixes import delayed\n",
    "from joblib import Parallel\n",
    "import warnings\n",
    "\n",
    "# отключаем экспоненциальное представление\n",
    "np.set_printoptions(precision=None, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'pear', 'apple', 'orange', 'pear', 'apple'], dtype='<U6')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пример 3 классов\n",
    "y_trn = np.array(['apple', 'pear', 'apple', \n",
    "                  'orange', 'pear', 'apple'])\n",
    "y_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 2, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строковые метки преобразовываем в целочисленные\n",
    "le = LabelEncoder()\n",
    "y_trn = le.fit_transform(y_trn)\n",
    "y_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
       "       'Class_7', 'Class_8', 'Class_9'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем набор\n",
    "otto = pd.read_csv('Data/ottogroup_train.csv')\n",
    "\n",
    "# удаляем id из набора\n",
    "otto.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# формируем массив меток и массив признаков,\n",
    "# преобразуем в массивы NumPy\n",
    "X_otto = otto.drop('target', axis=1).values\n",
    "y_otto = otto['target'].values\n",
    "\n",
    "# смотрим метки классов\n",
    "np.unique(y_otto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создание экземпляра класса LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# строковые метки преобразовываем в целочисленные\n",
    "y_otto = le.fit_transform(y_otto)\n",
    "np.unique(y_otto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем набор на обучающую и тестовую выборки \n",
    "X_otto_train, X_otto_test, y_otto_train, y_otto_test = train_test_split(\n",
    "    X_otto, y_otto, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем конвейер - экземпляр класса Pipeline\n",
    "inh_lr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('logreg', LogisticRegression(solver='newton-cg', \n",
    "                                  multi_class='multinomial'))\n",
    "])\n",
    "\n",
    "# применяем LogisticRegression для\n",
    "# многоклассовой классификации\n",
    "# естественным образом\n",
    "inh_lr_pipe.fit(X_otto_train, y_otto_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.025, 0.514, 0.135, 0.06 , 0.09 , 0.03 , 0.084, 0.044, 0.019],\n",
       "       [0.013, 0.059, 0.067, 0.002, 0.   , 0.098, 0.748, 0.001, 0.011],\n",
       "       [0.004, 0.007, 0.002, 0.   , 0.   , 0.934, 0.037, 0.009, 0.006],\n",
       "       [0.003, 0.001, 0.   , 0.748, 0.   , 0.219, 0.015, 0.   , 0.013],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем вероятности классов зависимой\n",
    "# переменной для тестовой выборки\n",
    "inh_lr_proba = np.round(\n",
    "    inh_lr_pipe.predict_proba(X_otto_test), 3)\n",
    "inh_lr_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.942,   2.076,   0.74 ,  -0.076,   0.337,  -0.776,   0.268,\n",
       "         -0.387,  -1.24 ],\n",
       "       [  1.088,   2.591,   2.717,  -0.648, -13.425,   3.091,   5.123,\n",
       "         -1.447,   0.91 ],\n",
       "       [ -0.326,   0.404,  -0.835,  -2.458,  -4.933,   5.258,   2.042,\n",
       "          0.653,   0.195],\n",
       "       [  0.403,  -1.058,  -2.34 ,   5.903,  -9.782,   4.674,   2.017,\n",
       "         -1.661,   1.845],\n",
       "       [  0.204,  -4.149,   0.794,  -7.618, -15.39 ,  17.632,   1.869,\n",
       "          7.978,  -1.32 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем значения решающей функции \n",
    "# для тестовой выборки\n",
    "inh_lr_dec_func = np.round(\n",
    "    inh_lr_pipe.decision_function(X_otto_test), 3)\n",
    "inh_lr_dec_func[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 5, 3, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем прогнозы для тестовой выборки\n",
    "inh_lr_pred = inh_lr_pipe.predict(X_otto_test)\n",
    "inh_lr_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем конвейер - экземпляр класса Pipeline\n",
    "ovr_lr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('logreg', LogisticRegression(solver='newton-cg', \n",
    "                                  multi_class='ovr'))\n",
    "])\n",
    "\n",
    "# применяем LogisticRegression для\n",
    "# многоклассовой классификации\n",
    "# по схеме one-vs-rest\n",
    "ovr_lr_pipe.fit(X_otto_train, y_otto_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.066, 0.42 , 0.137, 0.039, 0.111, 0.057, 0.083, 0.066, 0.021],\n",
       "       [0.019, 0.103, 0.13 , 0.008, 0.   , 0.045, 0.655, 0.001, 0.038],\n",
       "       [0.009, 0.061, 0.02 , 0.002, 0.   , 0.844, 0.046, 0.009, 0.008],\n",
       "       [0.008, 0.008, 0.006, 0.447, 0.   , 0.456, 0.033, 0.   , 0.04 ],\n",
       "       [0.   , 0.   , 0.008, 0.   , 0.   , 0.99 , 0.   , 0.002, 0.   ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем вероятности классов зависимой\n",
    "# переменной для тестовой выборки\n",
    "ovr_lr_proba = np.round(\n",
    "    ovr_lr_pipe.predict_proba(X_otto_test), 3)\n",
    "ovr_lr_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.023,  -0.858,  -2.231,  -3.555,  -2.466,  -3.165,  -2.768,\n",
       "         -3.019,  -4.201],\n",
       "       [ -3.913,  -2.134,  -1.868,  -4.742, -17.881,  -3.017,   0.717,\n",
       "         -7.213,  -3.2  ],\n",
       "       [ -4.639,  -2.605,  -3.758,  -5.887,  -8.113,   2.842,  -2.907,\n",
       "         -4.638,  -4.732],\n",
       "       [ -4.709,  -4.74 ,  -4.968,  -0.086, -14.566,  -0.049,  -3.299,\n",
       "         -8.045,  -3.097],\n",
       "       [-10.845,  -9.92 ,  -4.786, -14.167, -22.513,  10.257,  -9.421,\n",
       "         -6.303, -13.133]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем значения решающей функции \n",
    "# для тестовой выборки\n",
    "ovr_lr_dec_func = np.round(\n",
    "    ovr_lr_pipe.decision_function(X_otto_test), 3)\n",
    "ovr_lr_dec_func[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 5, 5, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем прогнозы для тестовой выборки\n",
    "ovr_lr_pred = ovr_lr_pipe.predict(X_otto_test)\n",
    "ovr_lr_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем конвейер - экземпляр класса Pipeline\n",
    "lr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('logreg', LogisticRegression(solver='newton-cg'))\n",
    "])\n",
    "\n",
    "# создаем экземпляр класса OneVsRestClassifier\n",
    "lr_ovr_classifier = OneVsRestClassifier(lr_pipe)\n",
    "# применяем LogisticRegression для многоклассовой \n",
    "# классификации по схеме one-vs-rest через\n",
    "# класс OneVsRestClassifier\n",
    "lr_ovr_classifier.fit(X_otto_train, y_otto_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.066, 0.42 , 0.137, 0.039, 0.111, 0.057, 0.083, 0.066, 0.021],\n",
       "       [0.019, 0.103, 0.13 , 0.008, 0.   , 0.045, 0.655, 0.001, 0.038],\n",
       "       [0.009, 0.061, 0.02 , 0.002, 0.   , 0.844, 0.046, 0.009, 0.008],\n",
       "       [0.008, 0.008, 0.006, 0.447, 0.   , 0.456, 0.033, 0.   , 0.04 ],\n",
       "       [0.   , 0.   , 0.008, 0.   , 0.   , 0.99 , 0.   , 0.002, 0.   ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем вероятности классов зависимой\n",
    "# переменной для тестовой выборки\n",
    "lr_ovr_classifier_proba = np.round(\n",
    "    lr_ovr_classifier.predict_proba(X_otto_test), 3)\n",
    "lr_ovr_classifier_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.023,  -0.858,  -2.231,  -3.555,  -2.466,  -3.165,  -2.768,\n",
       "         -3.019,  -4.201],\n",
       "       [ -3.913,  -2.134,  -1.868,  -4.742, -17.881,  -3.017,   0.717,\n",
       "         -7.213,  -3.2  ],\n",
       "       [ -4.639,  -2.605,  -3.758,  -5.887,  -8.113,   2.842,  -2.907,\n",
       "         -4.638,  -4.732],\n",
       "       [ -4.709,  -4.74 ,  -4.968,  -0.086, -14.566,  -0.049,  -3.299,\n",
       "         -8.045,  -3.097],\n",
       "       [-10.845,  -9.92 ,  -4.786, -14.167, -22.513,  10.257,  -9.421,\n",
       "         -6.303, -13.133]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем значения решающей функции \n",
    "# для тестовой выборки\n",
    "lr_ovr_classifier_dec_func = np.round(\n",
    "    lr_ovr_classifier.decision_function(X_otto_test), 3)\n",
    "lr_ovr_classifier_dec_func[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 5, 5, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем прогнозы для тестовой выборки\n",
    "lr_ovr_classifier_pred = lr_ovr_classifier.predict(X_otto_test)\n",
    "lr_ovr_classifier_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем экземпляр класса OneVsOneClassifier\n",
    "lr_ovo_classifier = OneVsOneClassifier(lr_pipe)\n",
    "# применяем LogisticRegression для многоклассовой \n",
    "# классификации по схеме one-vs-one через\n",
    "# класс OneVsOneClassifier\n",
    "lr_ovo_classifier.fit(X_otto_train, y_otto_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.724,  8.312,  7.295,  5.299,  4.233,  0.695,  6.283,  2.717,\n",
       "         0.684],\n",
       "       [ 4.279,  5.325,  6.322,  0.704, -0.33 ,  7.316,  8.325,  1.687,\n",
       "         2.734],\n",
       "       [ 0.688,  6.318,  5.313,  1.693, -0.328,  8.326,  7.321,  3.777,\n",
       "         2.701],\n",
       "       [ 3.289,  4.052,  2.698,  7.328, -0.33 ,  8.326,  3.774,  0.68 ,\n",
       "         6.322],\n",
       "       [ 1.672,  5.324,  6.33 ,  0.673,  1.669,  8.331,  4.321,  6.32 ,\n",
       "         1.673]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем значения решающей функции \n",
    "# для тестовой выборки\n",
    "lr_ovo_classifier_dec_func = np.round(\n",
    "    lr_ovo_classifier.decision_function(X_otto_test), 3)\n",
    "lr_ovo_classifier_dec_func[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 5, 5, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем прогнозы для тестовой выборки\n",
    "lr_ovo_classifier_pred = lr_ovo_classifier.predict(X_otto_test)\n",
    "lr_ovo_classifier_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем игрушечные данные\n",
    "\n",
    "# создаем обучающий массив признаков\n",
    "X_trn = np.array([[4.2, 1.5],\n",
    "                  [1.4, 2.1],\n",
    "                  [3.1, 0.5],\n",
    "                  [1.3, 2.2],\n",
    "                  [6.9, 4.5],\n",
    "                  [7.9, 7.1]])\n",
    "\n",
    "# создаем обучающий массив меток\n",
    "y_trn = np.array([0, 2, 0, 1, 2, 0])\n",
    "\n",
    "# создаем тестовый массив признаков\n",
    "X_tst = np.array([[2.8, 3.5],\n",
    "                  [1.1, 1.8],\n",
    "                  [8.9, 8.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем класс, выдающий константные прогнозы\n",
    "class _ConstantPredictor():\n",
    "    def fit(self, X, y):\n",
    "        self.y_ = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.repeat(self.y_, X.shape[0])\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.repeat(self.y_, X.shape[0])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_ = self.y_.astype(np.float64)\n",
    "        return np.repeat([np.hstack([1 - y_, y_])], \n",
    "                         X.shape[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая обучает отдельный \n",
    "# бинарный классификатор\n",
    "def _fit_binary(estimator, X, y, classes=None):\n",
    "    \"\"\"\n",
    "    Обучает отдельный бинарный классификатор.\n",
    "    \"\"\"\n",
    "    unique_y = np.unique(y)\n",
    "    if len(unique_y) == 1:\n",
    "        estimator = _ConstantPredictor().fit(X, unique_y)\n",
    "    else:\n",
    "        estimator = clone(estimator)\n",
    "        estimator.fit(X, y)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая обучает отдельный \n",
    "# бинарный классификатор по схеме one-vs-one\n",
    "def _fit_ovo_binary(estimator, X, y, i, j, verbose):\n",
    "    \"\"\"\n",
    "    Обучает отдельный бинарный \n",
    "    классификатор (one-vs-one).\n",
    "    \"\"\"\n",
    "    cond = np.logical_or(y == i, y == j)\n",
    "    y = y[cond]\n",
    "    y_binary = np.empty(y.shape, int)\n",
    "    y_binary[y == i] = 0\n",
    "    y_binary[y == j] = 1\n",
    "    indcond = np.arange(X.shape[0])[cond]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"cравниваем класс {i} с классом {j}\")\n",
    "        print(f\"индексы наблюдений, участвующих в сравнении:\\n{indcond}\\n\")\n",
    "    \n",
    "    return (\n",
    "        _fit_binary(\n",
    "            estimator,\n",
    "            _safe_split(estimator, X, None, indices=indcond)[0],\n",
    "            y_binary,\n",
    "            classes=[i, j],\n",
    "        ),\n",
    "        indcond,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая выдает прогнозы с\n",
    "# помощью отдельного бинарного классификатора\n",
    "def _predict_binary(estimator, X):\n",
    "    \"\"\"\n",
    "    Выдает прогнозы с помощью отдельного \n",
    "    бинарного классификатора.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # значения решающей функции\n",
    "        score = np.ravel(estimator.decision_function(X))\n",
    "    except (AttributeError, NotImplementedError):\n",
    "        # вероятности положительного класса\n",
    "        score = estimator.predict_proba(X)[:, 1]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая задает порог для\n",
    "# прогнозов бинарного классификатора\n",
    "def _threshold_for_binary_predict(estimator):\n",
    "    \"\"\"\n",
    "    Задает порог для прогнозов \n",
    "    бинарного классификатора.\n",
    "    \"\"\"\n",
    "    # если есть метод .decision_function()\n",
    "    if hasattr(estimator, \"decision_function\"):\n",
    "        return 0.0\n",
    "    # в противном случае, т.е. если есть метод\n",
    "    # .predict_proba()\n",
    "    else:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая вычисляет итоговые уверенности на основе\n",
    "# результатов многоклассовой классификации по схеме one-vs-one\n",
    "def _ovr_decision_function(predictions, confidences, n_classes, verbose):\n",
    "    \"\"\"\n",
    "    Вычисляет итоговые уверенности, исходя из результатов OvO.\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    predictions : массив формы (n_samples, n_classifiers)\n",
    "        Классы, спрогнозированные каждым бинарным классификатором.\n",
    "    confidences : массив формы (n_samples, n_classifiers)\n",
    "        Значения решающей функции или спрогнозированные вероятности\n",
    "        положительного класса, полученные с помощью каждого\n",
    "        бинарного классификатора.\n",
    "    n_classes : int\n",
    "        Количество классов. n_classifiers должно быть\n",
    "        ``n_classes * (n_classes - 1 ) / 2``.\n",
    "    \"\"\"\n",
    "    n_samples = predictions.shape[0]\n",
    "    votes = np.zeros((n_samples, n_classes))\n",
    "    sum_of_confidences = np.zeros((n_samples, n_classes))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"инициализируем матрицу голосов:\\n{votes}\\n\")\n",
    "        print(f\"инициализируем матрицу сумм \" \n",
    "              f\"уверенностей:\\n{sum_of_confidences}\\n\")\n",
    "\n",
    "    k = 0\n",
    "    for i in range(n_classes):\n",
    "        for j in range(i + 1, n_classes):\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"сравниваем класс {i} с классом {j}\\n\")\n",
    "            \n",
    "            sum_of_confidences[:, i] -= confidences[:, k]\n",
    "            sum_of_confidences[:, j] += confidences[:, k]\n",
    "            votes[predictions[:, k] == 0, i] += 1\n",
    "            votes[predictions[:, k] == 1, j] += 1\n",
    "            k += 1\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"матрица голосов:\\n{votes}\\n\")\n",
    "                print(f\"матрица сумм уверенностей:\\n{sum_of_confidences}\\n\")\n",
    "\n",
    "    # Выполняем монотонное преобразование сумм уверенностей в (-1/3, 1/3)\n",
    "    # и потом добавим к голосам. Монотонное преобразование выглядит так:\n",
    "    # f: x -> x / (3 * (|x| + 1)), используем 1/3 вместо 1/2, чтобы\n",
    "    # не изменить порядок голосования. \n",
    "    # Мотивация состоит в том, чтобы использовать степени уверенности \n",
    "    # как способ разорвать связи в голосовании (ситуации, когда у\n",
    "    # нескольких классов - одинаковое количество голосов), не изменяя\n",
    "    # какое-либо решение на противоположное, исходя из разницы в\n",
    "    # в 1 голос.\n",
    "    transformed_confidences = sum_of_confidences / (\n",
    "        3 * (np.abs(sum_of_confidences) + 1)\n",
    "    )\n",
    "    \n",
    "    # получаем итоговые суммы уверенностей\n",
    "    final_confidences = votes + transformed_confidences\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"подвергаем матрицу сумм уверенностей монотонному\\n\" \n",
    "              \"преобразованию x / (3 * (|x| + 1))\\n\")\n",
    "        print(f\"матрица преобразованных сумм уверенностей:\\n\" \n",
    "              f\"{transformed_confidences}\\n\")       \n",
    "        print(f\"матрица итоговых сумм уверенностей:\\n\" \n",
    "              f\"{final_confidences}\\n\")\n",
    "    \n",
    "    return final_confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализуем собственный класс, выполняющий многоклассовую \n",
    "# классификацию по схеме one-vs-one\n",
    "class CustomOneVsOneClassifier(MetaEstimatorMixin, \n",
    "                               ClassifierMixin, \n",
    "                               BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator, n_jobs=None, verbose=False):\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает соответствующие классификаторы.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : массив формы (n_samples, n_features)\n",
    "            Массив признаков.\n",
    "        y : массив формы (n_samples,)\n",
    "            Массив меток.\n",
    "            \n",
    "        Возвращает\n",
    "        -------\n",
    "        self : объект\n",
    "            Обученная модель.\n",
    "        \"\"\"\n",
    "\n",
    "        # записываем уникальные значения y\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        if len(self.classes_) == 1:\n",
    "            raise ValueError(\n",
    "                \"CustomOneVsOneClassifier нельзя обучить, \"\n",
    "                \"если нет ни одного класса.\"\n",
    "            )\n",
    "        # записываем количество классов\n",
    "        self.n_classes = self.classes_.shape[0]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"количество классов: {self.n_classes}\\n\")\n",
    "        \n",
    "        # записываем список из двух кортежей, количество элементов\n",
    "        # в кортежах определяется n_classes * (n_classes - 1 ) / 2\n",
    "        # бинарных классификаторов, в первый кортеж записаны \n",
    "        # экземпляры моделей - бинарных классификаторов, во второй \n",
    "        # кортеж записаны массивы наблюдений, которые использовались \n",
    "        # для обучения соответствующего бинарного классификатора\n",
    "        estimators_indices = list(\n",
    "            zip(\n",
    "                *(\n",
    "                    Parallel(n_jobs=self.n_jobs)(\n",
    "                        delayed(_fit_ovo_binary)(\n",
    "                            self.estimator, X, y, self.classes_[i], \n",
    "                            self.classes_[j], self.verbose\n",
    "                        )\n",
    "                        for i in range(self.n_classes)\n",
    "                        for j in range(i + 1, self.n_classes)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # записываем кортеж, состоящий из моделей \n",
    "        # - бинарных классификаторов\n",
    "        self.estimators_ = estimators_indices[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Выдает метку класса с наибольшей уверенностью \n",
    "        для каждого наблюдения в массиве признаков X.\n",
    "        Прогнозом будет ``argmax(decision_function(X), axis=1)``.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : массив формы (n_samples, n_features)\n",
    "            Массив признаков.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y : массив формы [n_samples]\n",
    "            Массив спрогнозированных меток классов.\n",
    "        \"\"\"\n",
    "        # получаем значения решающей функции\n",
    "        Y = self.decision_function(X)\n",
    "        # если 2 класса\n",
    "        if self.n_classes == 2:\n",
    "            # задаем порог\n",
    "            thresh = _threshold_for_binary_predict(self.estimators_[0])\n",
    "            # получаем прогнозы на основе порога\n",
    "            pred = self.classes_[(Y > thresh).astype(int)]\n",
    "            return pred\n",
    "        pred = self.classes_[Y.argmax(axis=1)]\n",
    "        if self.verbose:\n",
    "            print(f\"Прогнозом будет индекс с максимальной\\n\"\n",
    "                  f\"итоговой суммой уверенностей:\\n{pred}\")\n",
    "        return pred\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Решающая функция OneVsOneClassifier.\n",
    "        Значения решающей функции для наблюдений вычисляются путем\n",
    "        добавления к голосам нормализованной суммы уверенностей,\n",
    "        вычисленных в результате попарных сравнений классов,\n",
    "        чтобы устраненить неоднозначность, когда классы получают\n",
    "        одинаковое количество голосов, образуя связь.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : массив формы (n_samples, n_features)\n",
    "            Массив признаков.\n",
    "            \n",
    "        Возвращает\n",
    "        -------\n",
    "        Y : массив формы (n_samples, n_classes) или (n_samples,)\n",
    "            Результат вызова .decision_function() итоговой модели.\n",
    "        \"\"\"\n",
    "        \n",
    "        # получаем массив, состыкованный из len(self.estimators_)\n",
    "        # массивов для получения прогнозов\n",
    "        Xs = [X] * len(self.estimators_)\n",
    "        \n",
    "        # получаем прогнозы с помощью бинарных классификаторов\n",
    "        predictions = np.vstack(\n",
    "            [est.predict(Xi) for est, Xi in zip(self.estimators_, Xs)]\n",
    "        ).T\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"матрица прогнозов бинарных \" \n",
    "                  f\"классификаторов:\\n{predictions}\\n\")\n",
    "        \n",
    "        # получаем уверенности с помощью бинарных классификаторов\n",
    "        confidences = np.vstack(\n",
    "            [_predict_binary(est, Xi) \n",
    "             for est, Xi in zip(self.estimators_, Xs)]\n",
    "        ).T\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"матрица уверенностей бинарных \" \n",
    "                  f\"классификаторов:\\n{confidences}\\n\")\n",
    "        \n",
    "        # получаем итоговые уверенности\n",
    "        Y = _ovr_decision_function(predictions, confidences, \n",
    "                                   len(self.classes_), self.verbose)\n",
    "        # если 2 класса\n",
    "        if self.n_classes == 2:\n",
    "            return Y[:, 1]\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество классов: 3\n",
      "\n",
      "cравниваем класс 0 с классом 1\n",
      "индексы наблюдений, участвующих в сравнении:\n",
      "[0 2 3 5]\n",
      "\n",
      "cравниваем класс 0 с классом 2\n",
      "индексы наблюдений, участвующих в сравнении:\n",
      "[0 1 2 4 5]\n",
      "\n",
      "cравниваем класс 1 с классом 2\n",
      "индексы наблюдений, участвующих в сравнении:\n",
      "[1 3 4]\n",
      "\n",
      "матрица прогнозов бинарных классификаторов:\n",
      "[[0 0 1]\n",
      " [1 1 1]\n",
      " [0 0 1]\n",
      " [1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "\n",
      "матрица уверенностей бинарных классификаторов:\n",
      "[[-2.04743668 -0.75518106  1.23741829]\n",
      " [ 0.54659607  0.47450729  0.14616936]\n",
      " [-1.38801103 -0.66553044  0.68037941]\n",
      " [ 0.66210856  0.54344122  0.11535615]\n",
      " [-3.50727061 -0.80156436  2.66134319]\n",
      " [-3.61460391 -0.34469341  3.34334993]]\n",
      "\n",
      "инициализируем матрицу голосов:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "инициализируем матрицу сумм уверенностей:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "сравниваем класс 0 с классом 1\n",
      "\n",
      "матрица голосов:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "матрица сумм уверенностей:\n",
      "[[ 2.04743668 -2.04743668  0.        ]\n",
      " [-0.54659607  0.54659607  0.        ]\n",
      " [ 1.38801103 -1.38801103  0.        ]\n",
      " [-0.66210856  0.66210856  0.        ]\n",
      " [ 3.50727061 -3.50727061  0.        ]\n",
      " [ 3.61460391 -3.61460391  0.        ]]\n",
      "\n",
      "сравниваем класс 0 с классом 2\n",
      "\n",
      "матрица голосов:\n",
      "[[2. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [2. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [2. 0. 0.]\n",
      " [2. 0. 0.]]\n",
      "\n",
      "матрица сумм уверенностей:\n",
      "[[ 2.80261774 -2.04743668 -0.75518106]\n",
      " [-1.02110336  0.54659607  0.47450729]\n",
      " [ 2.05354147 -1.38801103 -0.66553044]\n",
      " [-1.20554979  0.66210856  0.54344122]\n",
      " [ 4.30883496 -3.50727061 -0.80156436]\n",
      " [ 3.95929733 -3.61460391 -0.34469341]]\n",
      "\n",
      "сравниваем класс 1 с классом 2\n",
      "\n",
      "матрица голосов:\n",
      "[[2. 0. 1.]\n",
      " [0. 1. 2.]\n",
      " [2. 0. 1.]\n",
      " [0. 1. 2.]\n",
      " [2. 0. 1.]\n",
      " [2. 0. 1.]]\n",
      "\n",
      "матрица сумм уверенностей:\n",
      "[[ 2.80261774 -3.28485496  0.48223722]\n",
      " [-1.02110336  0.40042671  0.62067665]\n",
      " [ 2.05354147 -2.06839044  0.01484897]\n",
      " [-1.20554979  0.54675242  0.65879737]\n",
      " [ 4.30883496 -6.1686138   1.85977883]\n",
      " [ 3.95929733 -6.95795384  2.99865652]]\n",
      "\n",
      "подвергаем матрицу сумм уверенностей монотонному\n",
      "преобразованию x / (3 * (|x| + 1))\n",
      "\n",
      "матрица преобразованных сумм уверенностей:\n",
      "[[ 0.24567442 -0.25553996  0.10844805]\n",
      " [-0.16840692  0.09531064  0.12765792]\n",
      " [ 0.22417047 -0.22469874  0.00487723]\n",
      " [-0.18219944  0.11782804  0.13238454]\n",
      " [ 0.27054492 -0.28683434  0.2167742 ]\n",
      " [ 0.26611951 -0.29144652  0.249972  ]]\n",
      "\n",
      "матрица итоговых сумм уверенностей:\n",
      "[[ 2.24567442 -0.25553996  1.10844805]\n",
      " [-0.16840692  1.09531064  2.12765792]\n",
      " [ 2.22417047 -0.22469874  1.00487723]\n",
      " [-0.18219944  1.11782804  2.13238454]\n",
      " [ 2.27054492 -0.28683434  1.2167742 ]\n",
      " [ 2.26611951 -0.29144652  1.249972  ]]\n",
      "\n",
      "Прогнозом будет индекс с максимальной\n",
      "итоговой суммой уверенностей:\n",
      "[0 2 0 2 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим логистическую регрессию по схеме one-vs-one\n",
    "lr_ovo_cust_classifier = CustomOneVsOneClassifier(\n",
    "    LogisticRegression(), verbose=True).fit(X_trn, y_trn)\n",
    "# получим прогнозы для игрушечного \n",
    "# обучающего массива признаков\n",
    "lr_ovo_cust_classifier_tr_pred = lr_ovo_cust_classifier.predict(X_trn)\n",
    "lr_ovo_cust_classifier_tr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "матрица прогнозов бинарных классификаторов:\n",
      "[[0 1 1]\n",
      " [1 1 0]\n",
      " [0 0 1]]\n",
      "\n",
      "матрица уверенностей бинарных классификаторов:\n",
      "[[-0.25562981  0.40092909  0.86834572]\n",
      " [ 0.71850161  0.49027405 -0.00858272]\n",
      " [-4.10030643 -0.30173175  3.8903464 ]]\n",
      "\n",
      "инициализируем матрицу голосов:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "инициализируем матрицу сумм уверенностей:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "сравниваем класс 0 с классом 1\n",
      "\n",
      "матрица голосов:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "матрица сумм уверенностей:\n",
      "[[ 0.25562981 -0.25562981  0.        ]\n",
      " [-0.71850161  0.71850161  0.        ]\n",
      " [ 4.10030643 -4.10030643  0.        ]]\n",
      "\n",
      "сравниваем класс 0 с классом 2\n",
      "\n",
      "матрица голосов:\n",
      "[[1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [2. 0. 0.]]\n",
      "\n",
      "матрица сумм уверенностей:\n",
      "[[-0.14529928 -0.25562981  0.40092909]\n",
      " [-1.20877566  0.71850161  0.49027405]\n",
      " [ 4.40203817 -4.10030643 -0.30173175]]\n",
      "\n",
      "сравниваем класс 1 с классом 2\n",
      "\n",
      "матрица голосов:\n",
      "[[1. 0. 2.]\n",
      " [0. 2. 1.]\n",
      " [2. 0. 1.]]\n",
      "\n",
      "матрица сумм уверенностей:\n",
      "[[-0.14529928 -1.12397552  1.2692748 ]\n",
      " [-1.20877566  0.72708433  0.48169133]\n",
      " [ 4.40203817 -7.99065283  3.58861465]]\n",
      "\n",
      "подвергаем матрицу сумм уверенностей монотонному\n",
      "преобразованию x / (3 * (|x| + 1))\n",
      "\n",
      "матрица преобразованных сумм уверенностей:\n",
      "[[-0.04228859 -0.17639493  0.18644353]\n",
      " [-0.18242016  0.14032983  0.1083652 ]\n",
      " [ 0.27162823 -0.29625779  0.26068977]]\n",
      "\n",
      "матрица итоговых сумм уверенностей:\n",
      "[[ 0.95771141 -0.17639493  2.18644353]\n",
      " [-0.18242016  2.14032983  1.1083652 ]\n",
      " [ 2.27162823 -0.29625779  1.26068977]]\n",
      "\n",
      "Прогнозом будет индекс с максимальной\n",
      "итоговой суммой уверенностей:\n",
      "[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получим прогнозы для игрушечного \n",
    "# тестового массива признаков\n",
    "lr_ovo_cust_classifier_tst_pred = lr_ovo_cust_classifier.predict(X_tst)\n",
    "lr_ovo_cust_classifier_tst_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем экземпляр класса OutputCodeClassifier\n",
    "lr_ecoc_classifier = OutputCodeClassifier(lr_pipe)\n",
    "# применяем LogisticRegression для многоклассовой \n",
    "# классификации по схеме ECOC через\n",
    "# класс OutputCodeClassifier\n",
    "lr_ecoc_classifier.fit(X_otto_train, y_otto_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 5, 5, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем прогнозы для тестовой выборки\n",
    "lr_ecoc_classifier_pred = lr_ecoc_classifier.predict(X_otto_test)\n",
    "lr_ecoc_classifier_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализуем собственный класс, выполняющий\n",
    "# многоклассовую классификацию по схеме ECOC\n",
    "class CustomOutputCodeClassifier(MetaEstimatorMixin, \n",
    "                                 ClassifierMixin, \n",
    "                                 BaseEstimator):\n",
    "    \"\"\"\n",
    "    Класс, реализующий многоклассовую классификацию\n",
    "    согласно подходу Error-Correcting Output Code\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    estimator : объект - экземпляр класса \n",
    "        Экземпляр класса, в котором реализована модель \n",
    "        машинного обучения. У него должен быть либо метод \n",
    "        .decision_function(), либо метод .predict_proba().\n",
    "    code_size : float, значение по умолчанию 1.5\n",
    "        Процент от количества классов для создания кодовой книги.\n",
    "        Значение от 0 до 1 потребует меньшее количество \n",
    "        классификаторов, чем подход \"один против остальных\". \n",
    "        Значение выше 1 потребует большее число классификаторов,\n",
    "        чем подход \"один против остальных\".\n",
    "    metric: str, значение по умолчанию 'euclidean'\n",
    "        Метрика расстояния.\n",
    "    random_state : int, значение по умолчанию None\n",
    "        Стартовое значение генератора псевдослучайных чисел.\n",
    "    n_jobs : int, значение по умолчанию None\n",
    "        Количество ядер процессора для распараллеливания.\n",
    "    verbose: bool, значение по умолчанию False\n",
    "        Печатает процесс обучения.\n",
    "    \n",
    "    Атрибуты\n",
    "    ----------\n",
    "    estimators_ : список `int(n_classes * code_size)` классификаторов\n",
    "        Классификаторы, используемые для предсказания.\n",
    "    classes_ : ndarray of shape (n_classes,)\n",
    "        Массив с метками.\n",
    "    code_book_ : ndarray формы (n_classes, code_size)\n",
    "        Массив бинарных значений, содержащий код \n",
    "        каждого класса.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, estimator, code_size=1.5, metric='euclidean',\n",
    "                 random_state=None, n_jobs=None, verbose=False):\n",
    "        self.estimator = estimator\n",
    "        self.code_size = code_size\n",
    "        self.metric = metric\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает классификаторы.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : массив формы (n_samples, n_features)\n",
    "            Массив признаков.\n",
    "        y : массив формы (n_samples,)\n",
    "            Массив меток.\n",
    "            \n",
    "        Возвращает\n",
    "        -------\n",
    "        self : object\n",
    "            Обученная модель.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = self.classes_.shape[0]\n",
    "        if n_classes == 0:\n",
    "            raise ValueError(\n",
    "                \"CustomOutputCodeClassifier нельзя обучить, \"\n",
    "                \"если нет ни одного класса.\")\n",
    "        \n",
    "        code_size_ = int(n_classes * self.code_size)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"количество классов: {n_classes}\")\n",
    "            print(f\"code_size с поправкой на n_classes: {code_size_}\") \n",
    "            print(f\"размер кодовой книги n_classes x \"\n",
    "                  f\"code_size:  {n_classes} x {code_size_}\")\n",
    "            print(\"\")\n",
    "\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        self.code_book_ = rng.uniform(size=(n_classes, code_size_))\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"исходная кодовая книга:\\n{self.code_book_}\")\n",
    "            print(\"\")\n",
    "        \n",
    "        self.code_book_[self.code_book_ > 0.5] = 1\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"первая корректировка кодовой книги:\\n\"\n",
    "                  f\"все значения больше 0.5 приравниваем к 1:\\n\"\n",
    "                  f\"{self.code_book_}\\n\")\n",
    "\n",
    "        if hasattr(self.estimator, \"decision_function\"):\n",
    "            self.code_book_[self.code_book_ != 1] = -1\n",
    "        else:\n",
    "            self.code_book_[self.code_book_ != 1] = 0\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"проверка наличия метода .decision_function(): \"\n",
    "                  f\"{hasattr(self.estimator, 'decision_function')}\\n\")\n",
    "            print(f\"вторая корректировка кодовой книги:\\n\"\n",
    "                  f\"если есть метод .decision_function(), все значения,\\n\"\n",
    "                  f\"не являющиеся 1, приравниваем к -1\\n\"\n",
    "                  f\"если нет метода .decision_function(), все значения,\\n\"\n",
    "                  f\"не являющиеся 1, приравниваем к 0\\n\\n\"\n",
    "                  f\"{self.code_book_}\\n\")\n",
    "            \n",
    "        classes_index = {c: i for i, c in enumerate(self.classes_)}\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"индексы классов:\\n{classes_index}\")\n",
    "            print(\"\")\n",
    "\n",
    "        Y = np.array(\n",
    "            [self.code_book_[classes_index[y[i]]] \n",
    "             for i in range(y.shape[0])],\n",
    "            dtype=int,\n",
    "        )\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_binary)(self.estimator, X, Y[:, i]) \n",
    "            for i in range(Y.shape[1])\n",
    "        )\n",
    "        \n",
    "        if self.verbose:    \n",
    "            print(f\"массив меток:\\n{Y}\\n\")\n",
    "            print(\"_ConstantPredictor() нужен для ситуаций, когда \"\n",
    "                  \"столбец является константным\")\n",
    "            print(\"список обученных моделей:\\n\", self.estimators_)\n",
    "            print(\"\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Получаем прогнозы с помощью соответствующих классификаторов.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : массив формы (n_samples, n_features)\n",
    "            Data.\n",
    "        Массив признаков\n",
    "        -------\n",
    "        y : массив формы (n_samples,)\n",
    "            Массив спрогнозированных меток классов.\n",
    "        \"\"\"\n",
    "     \n",
    "        Y = np.array([_predict_binary(e, X) \n",
    "                      for e in self.estimators_]).T\n",
    "        dist = pairwise_distances(Y, self.code_book_,  \n",
    "                                  metric=self.metric)\n",
    "        pred = dist.argmin(axis=1)\n",
    "           \n",
    "        if self.verbose:\n",
    "            print(f\"прогнозы бинарных классификаторов:\\n{Y}\\n\")\n",
    "            print(f\"расстояния:\\n{dist}\\n\")\n",
    "            print(f\"итоговые прогнозы:\\n{pred}\")\n",
    "            \n",
    "        return self.classes_[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество классов: 3\n",
      "code_size с поправкой на n_classes: 4\n",
      "размер кодовой книги n_classes x code_size:  3 x 4\n",
      "\n",
      "исходная кодовая книга:\n",
      "[[0.37454012 0.95071431 0.73199394 0.59865848]\n",
      " [0.15601864 0.15599452 0.05808361 0.86617615]\n",
      " [0.60111501 0.70807258 0.02058449 0.96990985]]\n",
      "\n",
      "первая корректировка кодовой книги:\n",
      "все значения больше 0.5 приравниваем к 1:\n",
      "[[0.37454012 1.         1.         1.        ]\n",
      " [0.15601864 0.15599452 0.05808361 1.        ]\n",
      " [1.         1.         0.02058449 1.        ]]\n",
      "\n",
      "проверка наличия метода .decision_function(): True\n",
      "\n",
      "вторая корректировка кодовой книги:\n",
      "если есть метод .decision_function(), все значения,\n",
      "не являющиеся 1, приравниваем к -1\n",
      "если нет метода .decision_function(), все значения,\n",
      "не являющиеся 1, приравниваем к 0\n",
      "\n",
      "[[-1.  1.  1.  1.]\n",
      " [-1. -1. -1.  1.]\n",
      " [ 1.  1. -1.  1.]]\n",
      "\n",
      "индексы классов:\n",
      "{0: 0, 1: 1, 2: 2}\n",
      "\n",
      "массив меток:\n",
      "[[-1  1  1  1]\n",
      " [ 1  1 -1  1]\n",
      " [-1  1  1  1]\n",
      " [-1 -1 -1  1]\n",
      " [ 1  1 -1  1]\n",
      " [-1  1  1  1]]\n",
      "\n",
      "_ConstantPredictor() нужен для ситуаций, когда столбец является константным\n",
      "список обученных моделей:\n",
      " [LogisticRegression(), LogisticRegression(), LogisticRegression(), <__main__._ConstantPredictor object at 0x7f81d07357f0>]\n",
      "\n",
      "прогнозы бинарных классификаторов:\n",
      "[[-0.95401785  2.54618834  0.63156985  1.        ]\n",
      " [-0.57325232  0.51581038 -1.16309398  1.        ]\n",
      " [-1.00934633  1.96254221  0.44723263  1.        ]\n",
      " [-0.54662428  0.42968979 -1.2602978   1.        ]\n",
      " [-0.72776042  3.88431188  0.85418853  1.        ]\n",
      " [-0.39706322  4.12206578  0.30924707  1.        ]]\n",
      "\n",
      "расстояния:\n",
      "[[1.59014261 3.90379127 2.97840634]\n",
      " [2.25732778 1.5831596  1.65413485]\n",
      " [1.11001199 3.29715422 2.65677294]\n",
      " [2.37481566 1.52227376 1.6688485 ]\n",
      " [2.90079823 5.2315038  3.83958672]\n",
      " [3.25391565 5.32101668 3.66240471]]\n",
      "\n",
      "итоговые прогнозы:\n",
      "[0 1 0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим логистическую регрессию по схеме ECOC\n",
    "lr_ecoc_cust_classifier = CustomOutputCodeClassifier(\n",
    "    LogisticRegression(), \n",
    "    random_state=42, verbose=True)\n",
    "lr_ecoc_cust_classifier.fit(X_trn, y_trn)\n",
    "# получим прогнозы для игрушечного\n",
    "# обучающего массива признаков\n",
    "lr_ecoc_cust_classifier_tr_pred = lr_ecoc_cust_classifier.predict(X_trn)\n",
    "lr_ecoc_cust_classifier_tr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5901426087931865\n",
      "2.2573277867455066\n",
      "1.1100119932923562\n",
      "2.3748156610146824\n",
      "2.9007982340747644\n",
      "3.2539156574237387\n",
      "\n",
      "3.903791269560861\n",
      "1.5831596056031012\n",
      "3.2971542252756194\n",
      "1.5222737545529064\n",
      "5.231503802427298\n",
      "5.321016679698285\n",
      "\n",
      "2.9784063383459958\n",
      "1.6541348484369\n",
      "2.6567729419829744\n",
      "1.6688485083435831\n",
      "3.839586721876623\n",
      "3.662404710791444\n"
     ]
    }
   ],
   "source": [
    "# пишем функцию, вычисляющую евклидово расстояние\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\" \n",
    "    Вычисляет евклидово расстояние \n",
    "    между двумя векторами. \n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for i in range(len(x1)):\n",
    "        distance += pow((x1[i] - x2[i]), 2)\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "# кодовая книга\n",
    "code_book = np.array([[-1.,  1.,  1.,  1.],\n",
    "                      [-1., -1., -1.,  1.],\n",
    "                      [ 1.,  1., -1.,  1.]])\n",
    "\n",
    "# прогнозы бинарных классификаторов\n",
    "binary_cl_pred = np.array(\n",
    "    [[-0.95401785, 2.54618834,  0.63156985, 1.],\n",
    "     [-0.57325232, 0.51581038, -1.16309398, 1.],\n",
    "     [-1.00934633, 1.96254221,  0.44723263, 1.],\n",
    "     [-0.54662428, 0.42968979, -1.2602978,  1.],\n",
    "     [-0.72776042, 3.88431188,  0.85418853, 1.],\n",
    "     [-0.39706322, 4.12206578,  0.30924707, 1.]]\n",
    ")\n",
    "\n",
    "# вычисляем расстояния\n",
    "print(euclidean_distance(code_book[0], binary_cl_pred[0]))\n",
    "print(euclidean_distance(code_book[0], binary_cl_pred[1]))\n",
    "print(euclidean_distance(code_book[0], binary_cl_pred[2]))\n",
    "print(euclidean_distance(code_book[0], binary_cl_pred[3]))\n",
    "print(euclidean_distance(code_book[0], binary_cl_pred[4]))\n",
    "print(euclidean_distance(code_book[0], binary_cl_pred[5]))\n",
    "print(\"\")\n",
    "print(euclidean_distance(code_book[1], binary_cl_pred[0]))\n",
    "print(euclidean_distance(code_book[1], binary_cl_pred[1]))\n",
    "print(euclidean_distance(code_book[1], binary_cl_pred[2]))\n",
    "print(euclidean_distance(code_book[1], binary_cl_pred[3]))\n",
    "print(euclidean_distance(code_book[1], binary_cl_pred[4]))\n",
    "print(euclidean_distance(code_book[1], binary_cl_pred[5]))\n",
    "print(\"\")\n",
    "print(euclidean_distance(code_book[2], binary_cl_pred[0]))\n",
    "print(euclidean_distance(code_book[2], binary_cl_pred[1]))\n",
    "print(euclidean_distance(code_book[2], binary_cl_pred[2]))\n",
    "print(euclidean_distance(code_book[2], binary_cl_pred[3]))\n",
    "print(euclidean_distance(code_book[2], binary_cl_pred[4]))\n",
    "print(euclidean_distance(code_book[2], binary_cl_pred[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "прогнозы бинарных классификаторов:\n",
      "[[-0.48172898  1.2365915  -0.98211356  1.        ]\n",
      " [-0.59286446  0.36135728 -1.20187549  1.        ]\n",
      " [-0.28194127  4.5849551   0.31210383  1.        ]]\n",
      "\n",
      "расстояния:\n",
      "[[2.06236625 2.29592384 1.50060529]\n",
      " [2.32849298 1.43520267 1.72795701]\n",
      " [3.72031082 5.78177726 4.02702036]]\n",
      "\n",
      "итоговые прогнозы:\n",
      "[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получим прогнозы для игрушечного \n",
    "# тестового массива признаков\n",
    "lr_ecoc_cust_classifier_tst_pred = lr_ecoc_cust_classifier.predict(X_tst)\n",
    "lr_ecoc_cust_classifier_tst_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
